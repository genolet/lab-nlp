{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2: Sentiment Analysis\n",
    "\n",
    "In this challenge we will learn sentiment analysis and practice performing sentiment analysis on Twitter tweets. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Sentiment analysis is to *systematically identify, extract, quantify, and study affective states and subjective information* based on texts ([reference](https://en.wikipedia.org/wiki/Sentiment_analysis)). In simple words, it's to understand whether a person is happy or unhappy in producing the piece of text. Why we (or rather, companies) care about sentiment in texts? It's because by understanding the sentiments in texts, we will be able to know if our customers are happy or unhappy about our products and services. If they are unhappy, the subsequent action is to figure out what have caused the unhappiness and make improvements.\n",
    "\n",
    "Basic sentiment analysis only understands the *positive* or *negative* (sometimes *neutral* too) polarities of the sentiment. More advanced sentiment analysis will also consider dimensions such as agreement, subjectivity, confidence, irony, and so on. In this challenge we will conduct the basic positive vs negative sentiment analysis based on real Twitter tweets.\n",
    "\n",
    "NLTK comes with a [sentiment analysis package](https://www.nltk.org/api/nltk.sentiment.html). This package is great for dummies to perform sentiment analysis because it requires only the textual data to make predictions. For example:\n",
    "\n",
    "```python\n",
    ">>> from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    ">>> txt = \"Ironhack is a Global Tech School ranked num 2 worldwide.  ",
    " ",
    "Our mission is to help people transform their careers and join a thriving community of tech professionals that love what they do.\"\n",
    ">>> analyzer = SentimentIntensityAnalyzer()\n",
    ">>> analyzer.polarity_scores(txt)\n",
    "{'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.8442}\n",
    "```\n",
    "\n",
    "In this challenge, however, you will not use NLTK's sentiment analysis package because in your Machine Learning training in the past 2 weeks you have learned how to make predictions more accurate than that. The [tweets data](https://www.kaggle.com/kazanova/sentiment140) we will be using today are already coded for the positive/negative sentiment. You will be able to use the Naïve Bayes classifier you learned in the lesson to predict the sentiment of tweets based on the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting Sentiment Analysis\n",
    "\n",
    "### Loading and Exploring Data\n",
    "\n",
    "The dataset we'll be using today is located on Kaggle (https://www.kaggle.com/kazanova/sentiment140). Once you have downloaded and imported the dataset, it you will need to define the columns names: df.columns = ['target','id','date','flag','user','text']\n",
    "\n",
    "*Notes:* \n",
    "\n",
    "* The dataset is huuuuge (1.6m tweets). When you develop your data analysis codes, you can sample a subset of the data (e.g. 20k records) so that you will save a lot of time when you test your codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/origenolet/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/origenolet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/origenolet/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", \n",
    "                  encoding='latin-1', header = None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['target','id','date','flag','user','text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1579740</th>\n",
       "      <td>4</td>\n",
       "      <td>2189983665</td>\n",
       "      <td>Tue Jun 16 01:26:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SarahMorrison</td>\n",
       "      <td>I love you LA. Its nice to be home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504647</th>\n",
       "      <td>0</td>\n",
       "      <td>2188186225</td>\n",
       "      <td>Mon Jun 15 21:26:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jjbabyMEOWZER</td>\n",
       "      <td>She back and i really want to see her but i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815879</th>\n",
       "      <td>4</td>\n",
       "      <td>1551270859</td>\n",
       "      <td>Sat Apr 18 08:36:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BigcityBrooke3</td>\n",
       "      <td>Tonight  is going to be Fucking amazing  &amp;lt;3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199512</th>\n",
       "      <td>0</td>\n",
       "      <td>1971455566</td>\n",
       "      <td>Sat May 30 07:09:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lilwldchld</td>\n",
       "      <td>@aholston aww...  I hope you get everything do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238232</th>\n",
       "      <td>4</td>\n",
       "      <td>1993226101</td>\n",
       "      <td>Mon Jun 01 10:02:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SarrisW</td>\n",
       "      <td>@aaronklein @mchesner   Being an artist type, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "1579740       4  2189983665  Tue Jun 16 01:26:25 PDT 2009  NO_QUERY   \n",
       "504647        0  2188186225  Mon Jun 15 21:26:57 PDT 2009  NO_QUERY   \n",
       "815879        4  1551270859  Sat Apr 18 08:36:26 PDT 2009  NO_QUERY   \n",
       "199512        0  1971455566  Sat May 30 07:09:13 PDT 2009  NO_QUERY   \n",
       "1238232       4  1993226101  Mon Jun 01 10:02:06 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \n",
       "1579740   SarahMorrison                I love you LA. Its nice to be home   \n",
       "504647    jjbabyMEOWZER  She back and i really want to see her but i do...  \n",
       "815879   BigcityBrooke3  Tonight  is going to be Fucking amazing  &lt;3333  \n",
       "199512       lilwldchld  @aholston aww...  I hope you get everything do...  \n",
       "1238232         SarrisW  @aaronklein @mchesner   Being an artist type, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(n = 20000, random_state = 50, replace = False)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Textual Data for Sentiment Analysis\n",
    "\n",
    "Now, apply the functions you have written in Challenge 1 to your whole data set. These functions include:\n",
    "\n",
    "* `clean_up()`\n",
    "\n",
    "* `tokenize()`\n",
    "\n",
    "* `stem_and_lemmatize()`\n",
    "\n",
    "* `remove_stopwords()`\n",
    "\n",
    "Create a new column called `text_processed` in the dataframe to contain the processed data. At the end, your `text_processed` column should contain lists of word tokens that are cleaned up. Your data should look like below:\n",
    "\n",
    "![Processed Data](data-cleaning-results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', ' ' , s)\n",
    "    s = re.sub(r'\\W+',' ',s) \n",
    "    s = re.sub(r'\\s+',' ',s) \n",
    "    s = re.sub(r'\\d+',' ',s) \n",
    "    s = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\" \", s)  \n",
    "    s = BeautifulSoup(s, 'lxml').get_text().strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = word_tokenize(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(l):\n",
    "    lst = []\n",
    "    lem = WordNetLemmatizer()\n",
    "    for item in l:\n",
    "        item = lem.lemmatize(item)\n",
    "        lst.append(item)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(l):   \n",
    "    stop_words = list(stopwords.words('english')) \n",
    "    for item in l:\n",
    "        if item in stop_words:\n",
    "            l.remove(item)\n",
    "        else:\n",
    "            pass\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1579740</th>\n",
       "      <td>4</td>\n",
       "      <td>2189983665</td>\n",
       "      <td>Tue Jun 16 01:26:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SarahMorrison</td>\n",
       "      <td>I love you LA. Its nice to be home</td>\n",
       "      <td>[love, la, nice, be, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504647</th>\n",
       "      <td>0</td>\n",
       "      <td>2188186225</td>\n",
       "      <td>Mon Jun 15 21:26:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jjbabyMEOWZER</td>\n",
       "      <td>She back and i really want to see her but i do...</td>\n",
       "      <td>[back, really, want, see, but, i, dont, enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815879</th>\n",
       "      <td>4</td>\n",
       "      <td>1551270859</td>\n",
       "      <td>Sat Apr 18 08:36:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BigcityBrooke3</td>\n",
       "      <td>Tonight  is going to be Fucking amazing  &amp;lt;3333</td>\n",
       "      <td>[tonight, going, be, fucking, amazing, lt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199512</th>\n",
       "      <td>0</td>\n",
       "      <td>1971455566</td>\n",
       "      <td>Sat May 30 07:09:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lilwldchld</td>\n",
       "      <td>@aholston aww...  I hope you get everything do...</td>\n",
       "      <td>[aholston, aww, hope, get, everything, done]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238232</th>\n",
       "      <td>4</td>\n",
       "      <td>1993226101</td>\n",
       "      <td>Mon Jun 01 10:02:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SarrisW</td>\n",
       "      <td>@aaronklein @mchesner   Being an artist type, ...</td>\n",
       "      <td>[aaronklein, mchesner, an, artist, type, t, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "1579740       4  2189983665  Tue Jun 16 01:26:25 PDT 2009  NO_QUERY   \n",
       "504647        0  2188186225  Mon Jun 15 21:26:57 PDT 2009  NO_QUERY   \n",
       "815879        4  1551270859  Sat Apr 18 08:36:26 PDT 2009  NO_QUERY   \n",
       "199512        0  1971455566  Sat May 30 07:09:13 PDT 2009  NO_QUERY   \n",
       "1238232       4  1993226101  Mon Jun 01 10:02:06 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \\\n",
       "1579740   SarahMorrison                I love you LA. Its nice to be home    \n",
       "504647    jjbabyMEOWZER  She back and i really want to see her but i do...   \n",
       "815879   BigcityBrooke3  Tonight  is going to be Fucking amazing  &lt;3333   \n",
       "199512       lilwldchld  @aholston aww...  I hope you get everything do...   \n",
       "1238232         SarrisW  @aaronklein @mchesner   Being an artist type, ...   \n",
       "\n",
       "                                            text_processed  \n",
       "1579740                         [love, la, nice, be, home]  \n",
       "504647   [back, really, want, see, but, i, dont, enough...  \n",
       "815879          [tonight, going, be, fucking, amazing, lt]  \n",
       "199512        [aholston, aww, hope, get, everything, done]  \n",
       "1238232  [aaronklein, mchesner, an, artist, type, t, re...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = [clean_up, tokenize, stem_and_lemmatize, remove_stopwords]\n",
    "cols = [\"text\", \"text_processed\", \"text_processed\", \"text_processed\"]\n",
    "for function, col in zip(functions, cols):\n",
    "    data[\"text_processed\"] = data[col].apply(function)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bag of Words\n",
    "\n",
    "The purpose of this step is to create a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) from the processed data. The bag of words contains all the unique words in your whole text body (a.k.a. *corpus*) with the number of occurrence of each word. It will allow you to understand which words are the most important features across the whole corpus.\n",
    "\n",
    "Also, you can imagine you will have a massive set of words. The less important words (i.e. those of very low number of occurrence) do not contribute much to the sentiment. Therefore, you only need to use the most important words to build your feature set in the next step. In our case, we will use the top 5,000 words with the highest frequency to build the features.\n",
    "\n",
    "In the cell below, combine all the words in `text_processed` and calculate the frequency distribution of all words. A convenient library to calculate the term frequency distribution is NLTK's `FreqDist` class ([documentation](https://www.nltk.org/api/nltk.html#module-nltk.probability)). Then select the top 5,000 words from the frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'la',\n",
       " 'nice',\n",
       " 'be',\n",
       " 'home',\n",
       " 'back',\n",
       " 'really',\n",
       " 'want',\n",
       " 'see',\n",
       " 'but',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'enough',\n",
       " 'courage',\n",
       " 'im',\n",
       " 'scared',\n",
       " 'do',\n",
       " 'alone',\n",
       " 'tonight',\n",
       " 'going',\n",
       " 'be',\n",
       " 'fucking',\n",
       " 'amazing',\n",
       " 'lt',\n",
       " 'aholston',\n",
       " 'aww',\n",
       " 'hope',\n",
       " 'get',\n",
       " 'everything',\n",
       " 'done',\n",
       " 'aaronklein',\n",
       " 'mchesner',\n",
       " 'an',\n",
       " 'artist',\n",
       " 'type',\n",
       " 't',\n",
       " 'resist',\n",
       " 'jab',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'everyone',\n",
       " 'ready',\n",
       " 'start',\n",
       " 'another',\n",
       " 'exciting',\n",
       " 'week',\n",
       " 'degree',\n",
       " 'outside',\n",
       " 'net',\n",
       " 'at',\n",
       " 'hme',\n",
       " 'rbflygal',\n",
       " 's',\n",
       " 'bridal',\n",
       " 'shower',\n",
       " 'without',\n",
       " 'sex',\n",
       " 'toy',\n",
       " 'going',\n",
       " 'do',\n",
       " 'uni',\n",
       " 'work',\n",
       " 'wish',\n",
       " 'luck',\n",
       " 'thisisdavina',\n",
       " 'awesome',\n",
       " 'ack',\n",
       " 'sure',\n",
       " 'mum',\n",
       " 'bought',\n",
       " 'workout',\n",
       " 'i',\n",
       " 'swear',\n",
       " 'never',\n",
       " 'stop',\n",
       " 'complaining',\n",
       " 'still',\n",
       " 'doe',\n",
       " 'rosyantoine',\n",
       " 'doe',\n",
       " 'do',\n",
       " 'shayboo',\n",
       " 'lyfe',\n",
       " 'yeah',\n",
       " 'm',\n",
       " 'going',\n",
       " 'be',\n",
       " 'meeting',\n",
       " 'on',\n",
       " 'july',\n",
       " 'th',\n",
       " 'wonder',\n",
       " 'whether',\n",
       " 'fukuoka',\n",
       " 'knew',\n",
       " 'iata',\n",
       " 'code',\n",
       " 'wa',\n",
       " 'going',\n",
       " 'be',\n",
       " 'fuk',\n",
       " 'two',\n",
       " 'day',\n",
       " 'till',\n",
       " 'leave',\n",
       " 'fuk',\n",
       " 'today',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'good',\n",
       " 'day',\n",
       " 'either',\n",
       " 'buy',\n",
       " 'shoe',\n",
       " 'make',\n",
       " 'print',\n",
       " 'talk',\n",
       " 'business',\n",
       " 'll',\n",
       " 'see',\n",
       " 'happens',\n",
       " 'whoop',\n",
       " 'ad',\n",
       " 'phone',\n",
       " 'call',\n",
       " 'ma',\n",
       " 'dinner',\n",
       " 'nearly',\n",
       " 'ready',\n",
       " 'so',\n",
       " 'forgotten',\n",
       " 'not',\n",
       " 'time',\n",
       " 'it',\n",
       " 'stupid',\n",
       " 'work',\n",
       " 'emmmmm',\n",
       " 'someone',\n",
       " 'clever',\n",
       " 'using',\n",
       " 'twitter',\n",
       " 'their',\n",
       " 'phone',\n",
       " 'lol',\n",
       " 'wish',\n",
       " 'were',\n",
       " 'the',\n",
       " 'comp',\n",
       " 'it',\n",
       " 'soooo',\n",
       " 'boring',\n",
       " 'pauljmcmahon',\n",
       " 'decided',\n",
       " 'turn',\n",
       " 'sky',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'nope',\n",
       " 'stuck',\n",
       " 'now',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'anyone',\n",
       " 'following',\n",
       " 'please',\n",
       " 'a',\n",
       " 'follow',\n",
       " 'a',\n",
       " 'well',\n",
       " 'otherwise',\n",
       " 'will',\n",
       " 'deleted',\n",
       " 'not',\n",
       " 'miss',\n",
       " 'midshorelife',\n",
       " 'our',\n",
       " 'service',\n",
       " 'm',\n",
       " 'about',\n",
       " 'farmer',\n",
       " 'market',\n",
       " 'watching',\n",
       " 'quot',\n",
       " 'lucky',\n",
       " 'one',\n",
       " 'quot',\n",
       " 'need',\n",
       " 'movie',\n",
       " 'buddy',\n",
       " 'wetaworkshop',\n",
       " 'bank',\n",
       " 'holiday',\n",
       " 'weekend',\n",
       " 'the',\n",
       " 'uk',\n",
       " 'so',\n",
       " 'lose',\n",
       " 'shiftywooten',\n",
       " 're',\n",
       " 'who',\n",
       " 'know',\n",
       " 'sadly',\n",
       " 'm',\n",
       " 'doing',\n",
       " 'houston',\n",
       " 'eringo_braless',\n",
       " 'can',\n",
       " 'quot',\n",
       " 'see',\n",
       " 'quot',\n",
       " 'the',\n",
       " 'web',\n",
       " 'phone',\n",
       " 'the',\n",
       " 'way',\n",
       " 'damn',\n",
       " 'game',\n",
       " 'going',\n",
       " 'just',\n",
       " 'might',\n",
       " 'see',\n",
       " 'lebron',\n",
       " 'a',\n",
       " 'knicks',\n",
       " 'jersey',\n",
       " 'next',\n",
       " 'year',\n",
       " 'am',\n",
       " 'sitting',\n",
       " 'and',\n",
       " 'feeling',\n",
       " 'sad',\n",
       " 'i',\n",
       " 'broke',\n",
       " 'with',\n",
       " 'boyfriend',\n",
       " 'now',\n",
       " 'im',\n",
       " 'single',\n",
       " 'dear',\n",
       " 'wetzels',\n",
       " 'bought',\n",
       " 'pretzel',\n",
       " 'dog',\n",
       " 'you',\n",
       " 'auntie',\n",
       " 'anne',\n",
       " 'is',\n",
       " 'cash',\n",
       " 'only',\n",
       " 'hillsong',\n",
       " 'tom',\n",
       " 'night',\n",
       " 'dad',\n",
       " 'birthday',\n",
       " 'wish',\n",
       " 'could',\n",
       " 'see',\n",
       " 'on',\n",
       " 'bday',\n",
       " 'though',\n",
       " 'anonymouspinay',\n",
       " 'if',\n",
       " 'had',\n",
       " 'place',\n",
       " 'd',\n",
       " 'let',\n",
       " 'walk',\n",
       " 'around',\n",
       " 'naked',\n",
       " 'queenclariss',\n",
       " 'idk',\n",
       " 'sent',\n",
       " 'a',\n",
       " 'message',\n",
       " 'twitter',\n",
       " 'it',\n",
       " 'came',\n",
       " 'you',\n",
       " 'registered',\n",
       " 'imma',\n",
       " 'go',\n",
       " 'lay',\n",
       " 'n',\n",
       " 'watch',\n",
       " 't',\n",
       " 'v',\n",
       " 'head',\n",
       " 'killin',\n",
       " 'miss',\n",
       " 'area',\n",
       " 'meeting',\n",
       " 'tonight',\n",
       " 'due',\n",
       " 'the',\n",
       " 'work',\n",
       " 'schedule',\n",
       " 'still',\n",
       " 'able',\n",
       " 'to',\n",
       " 'go',\n",
       " 'hang',\n",
       " 'with',\n",
       " 'people',\n",
       " 'tonight',\n",
       " 'i',\n",
       " 'happy',\n",
       " 'leona',\n",
       " 'lewis',\n",
       " 'back',\n",
       " 'tour',\n",
       " 'you',\n",
       " 'catch',\n",
       " 'drift',\n",
       " 'have',\n",
       " 'withdrawn',\n",
       " 'spice',\n",
       " 'range',\n",
       " 'product',\n",
       " 'further',\n",
       " 'notice',\n",
       " 'nz',\n",
       " 'government',\n",
       " 'wrongly',\n",
       " 'belief',\n",
       " 'product',\n",
       " 'range',\n",
       " 'illegal',\n",
       " 'might',\n",
       " 'go',\n",
       " 'get',\n",
       " 'snicker',\n",
       " 'stupid',\n",
       " 'king',\n",
       " 'sized',\n",
       " 'one',\n",
       " 'broken',\n",
       " 'ugh',\n",
       " 'omarion',\n",
       " 'sooooo',\n",
       " 'doe',\n",
       " 'so',\n",
       " 'called',\n",
       " 'quot',\n",
       " 'sex',\n",
       " 'tape',\n",
       " 'quot',\n",
       " 'go',\n",
       " 'public',\n",
       " 'figured',\n",
       " 'd',\n",
       " 'ask',\n",
       " 'star',\n",
       " 'am',\n",
       " 'sick',\n",
       " 'cold',\n",
       " 'doe',\n",
       " 'zack',\n",
       " 'efron',\n",
       " 'get',\n",
       " 'top',\n",
       " 'billing',\n",
       " 'matthew',\n",
       " 'perry',\n",
       " 'iamthecommodore',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'place',\n",
       " 'so',\n",
       " 'hot',\n",
       " 'agreat',\n",
       " 'run',\n",
       " 'hope',\n",
       " 'detroit',\n",
       " 'win',\n",
       " 'nd',\n",
       " 'game',\n",
       " 'buckhollywood',\n",
       " 'sex',\n",
       " 'city',\n",
       " 'amp',\n",
       " 'can',\n",
       " 'stop',\n",
       " 'rewatching',\n",
       " 'the',\n",
       " 'season',\n",
       " 'love',\n",
       " 'show',\n",
       " 'going',\n",
       " 'eat',\n",
       " 'my',\n",
       " 'aunt',\n",
       " 'soooon',\n",
       " 'getting',\n",
       " 'ready',\n",
       " 'changing',\n",
       " 'hope',\n",
       " 'today',\n",
       " 'a',\n",
       " 'goood',\n",
       " 'day',\n",
       " 'idk',\n",
       " 'miissss',\n",
       " 'himm',\n",
       " 'omg',\n",
       " 'hanadi',\n",
       " 'abusing',\n",
       " '_',\n",
       " 'mayonice',\n",
       " 'goodness',\n",
       " 'wa',\n",
       " 'wondering',\n",
       " 'the',\n",
       " 'hell',\n",
       " 'the',\n",
       " 'girl',\n",
       " 'let',\n",
       " 'publish',\n",
       " 'name',\n",
       " 'poor',\n",
       " 'thing',\n",
       " 'rockergirl',\n",
       " 'make',\n",
       " 'sad',\n",
       " 'joeymcintyre',\n",
       " 'ha',\n",
       " 'tendency',\n",
       " 'do',\n",
       " 'he',\n",
       " 'never',\n",
       " 'stick',\n",
       " 'around',\n",
       " 'long',\n",
       " 'tease',\n",
       " 'tjinkerson',\n",
       " 'lol',\n",
       " 'dm',\n",
       " 'those',\n",
       " 'll',\n",
       " 'include',\n",
       " 'in',\n",
       " 'next',\n",
       " 'week',\n",
       " 'so',\n",
       " 'catherinecas',\n",
       " 'can',\n",
       " 'also',\n",
       " 'play',\n",
       " 'tongits',\n",
       " 'your',\n",
       " 'pc',\n",
       " 'mac',\n",
       " 'download',\n",
       " 'game',\n",
       " 'enjoy',\n",
       " 'currently',\n",
       " 'trying',\n",
       " 'figure',\n",
       " 'where',\n",
       " 'fuck',\n",
       " 'went',\n",
       " 'it',\n",
       " 's',\n",
       " 'adorable',\n",
       " 'one',\n",
       " 'class',\n",
       " 'off',\n",
       " 'the',\n",
       " 'train',\n",
       " 'station',\n",
       " 'boa',\n",
       " 'noite',\n",
       " 'follower',\n",
       " 'weeelady',\n",
       " 'know',\n",
       " 'feeling',\n",
       " 'lol',\n",
       " 'hope',\n",
       " 'uncle',\n",
       " 'ok',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'running',\n",
       " 'around',\n",
       " 'today',\n",
       " 'do',\n",
       " 'sitting',\n",
       " 'rubbing',\n",
       " 'eye',\n",
       " 'hay',\n",
       " 'fever',\n",
       " 'singing',\n",
       " 'rather',\n",
       " 'tunlessly',\n",
       " 'the',\n",
       " 'arctic',\n",
       " 'monkey',\n",
       " 'not',\n",
       " 'wasted',\n",
       " 'saterday',\n",
       " 'want',\n",
       " 'go',\n",
       " 'jordanknight',\n",
       " 'shit',\n",
       " 'would',\n",
       " 'so',\n",
       " 'crazy',\n",
       " 'that',\n",
       " 'the',\n",
       " 'real',\n",
       " 'reason',\n",
       " 'good',\n",
       " 'luck',\n",
       " 'tonight',\n",
       " 'not',\n",
       " 'technical',\n",
       " 'difficulty',\n",
       " 'olliandlime',\n",
       " 'love',\n",
       " 'shoe',\n",
       " 'lurve',\n",
       " 'shoe',\n",
       " 'esp',\n",
       " 'red',\n",
       " 'shoe',\n",
       " 'waiting',\n",
       " 'red',\n",
       " 'boot',\n",
       " 'arrive',\n",
       " 'hoof',\n",
       " 'i',\n",
       " 'feed',\n",
       " 'daughter',\n",
       " 'shoe',\n",
       " 'fetish',\n",
       " 'mileycyrus',\n",
       " 'miss',\n",
       " 'im',\n",
       " 'wdw',\n",
       " 'watching',\n",
       " 'hannah',\n",
       " 'my',\n",
       " 'laptop',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'bluray',\n",
       " 'good',\n",
       " 'mornin',\n",
       " 'tweetie',\n",
       " 'pie',\n",
       " 'to',\n",
       " 'salon',\n",
       " 'work',\n",
       " 'great',\n",
       " 'a',\n",
       " 'flexible',\n",
       " 'job',\n",
       " 'cancerscore',\n",
       " 'course',\n",
       " 'moving',\n",
       " 'always',\n",
       " 'stressful',\n",
       " 'anything',\n",
       " 'help',\n",
       " 'you',\n",
       " 'know',\n",
       " 'you',\n",
       " 'be',\n",
       " 'a',\n",
       " 'new',\n",
       " 'house',\n",
       " 'yay',\n",
       " 'ijustine',\n",
       " 's',\n",
       " 'i',\n",
       " 'for',\n",
       " 'sm',\n",
       " 'turn',\n",
       " 'that',\n",
       " 'my',\n",
       " 'job',\n",
       " 'well',\n",
       " 'not',\n",
       " 'enough',\n",
       " 'outstanding',\n",
       " 'the',\n",
       " 'key',\n",
       " 'word',\n",
       " 'astridnonikpp',\n",
       " 'understand',\n",
       " 'really',\n",
       " 'well',\n",
       " 'aight',\n",
       " 'just',\n",
       " 'burnt',\n",
       " 'from',\n",
       " 'trying',\n",
       " 'take',\n",
       " 'pizza',\n",
       " 'outta',\n",
       " 'tha',\n",
       " 'oven',\n",
       " 'amp',\n",
       " 'pizza',\n",
       " 'wasnt',\n",
       " 'even',\n",
       " 'pau',\n",
       " 'haw',\n",
       " 'mayyyun',\n",
       " 'used',\n",
       " 'have',\n",
       " 'ghd',\n",
       " 'straightner',\n",
       " 'it',\n",
       " 'broke',\n",
       " 'half',\n",
       " 'feeling',\n",
       " 'better',\n",
       " 'want',\n",
       " 'somee',\n",
       " 'food',\n",
       " 'feel',\n",
       " 'fat',\n",
       " 'ashleymelchert',\n",
       " 'haha',\n",
       " 'cool',\n",
       " 'bean',\n",
       " 'wish',\n",
       " 'could',\n",
       " 'together',\n",
       " 'akkkkk',\n",
       " 'haven',\n",
       " 'they',\n",
       " 'invented',\n",
       " 'teleporting',\n",
       " 'booooo',\n",
       " 'tweetlord',\n",
       " 'a',\n",
       " 'twitter',\n",
       " 'role',\n",
       " 'playing',\n",
       " 'game',\n",
       " 'check',\n",
       " 'u',\n",
       " 'at',\n",
       " 'have',\n",
       " 'adorable',\n",
       " 'avatar',\n",
       " 'funky',\n",
       " 'item',\n",
       " 'tlgame',\n",
       " 'amazoe',\n",
       " 's',\n",
       " 'good',\n",
       " 'hear',\n",
       " 'thing',\n",
       " 'going',\n",
       " 'well',\n",
       " 'too',\n",
       " 'more',\n",
       " 'more',\n",
       " 'want',\n",
       " 'job',\n",
       " 'game',\n",
       " 'community',\n",
       " 'stuff',\n",
       " 'travel',\n",
       " 'don',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'leave',\n",
       " 'chicago',\n",
       " 'wish',\n",
       " 'would',\n",
       " 'update',\n",
       " 'going',\n",
       " 'learn',\n",
       " 'hoedown',\n",
       " 'throwdown',\n",
       " 'today',\n",
       " 'have',\n",
       " 'joystick',\n",
       " 'copy',\n",
       " 'flight',\n",
       " 'simulator',\n",
       " 'x',\n",
       " 'window',\n",
       " 's',\n",
       " 'time',\n",
       " 'fly',\n",
       " 'peanut',\n",
       " 'butter',\n",
       " 'brownie',\n",
       " 'blueberry',\n",
       " 'bagel',\n",
       " 'chocolate',\n",
       " 'ginger',\n",
       " 'crisp',\n",
       " 'oatmeal',\n",
       " 'icecream',\n",
       " 'yes',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'i',\n",
       " 't',\n",
       " 'eat',\n",
       " 'papercakes',\n",
       " 'snow',\n",
       " 'wonder',\n",
       " 's',\n",
       " 'cold',\n",
       " 'please',\n",
       " 'keep',\n",
       " 'at',\n",
       " 'ab',\n",
       " 'sk',\n",
       " 'border',\n",
       " 'don',\n",
       " 'want',\n",
       " 'this',\n",
       " 'weather',\n",
       " 'crazy',\n",
       " 'changed',\n",
       " 'background',\n",
       " 'picture',\n",
       " 'now',\n",
       " 's',\n",
       " 'cool',\n",
       " 'er',\n",
       " 'dehfamsincere',\n",
       " 'know',\n",
       " 'really',\n",
       " 'tired',\n",
       " 'night',\n",
       " 'tweats',\n",
       " 'thenolookpass',\n",
       " 'yeah',\n",
       " 'm',\n",
       " 'your',\n",
       " 'english',\n",
       " 'professor',\n",
       " 'late',\n",
       " 'submission',\n",
       " 'totally',\n",
       " 'fine',\n",
       " 'add',\n",
       " 'tomorrow',\n",
       " 'nocturnalie',\n",
       " 'anyway',\n",
       " 'now',\n",
       " 'abby',\n",
       " 'i',\n",
       " 'share',\n",
       " 'our',\n",
       " 'crop',\n",
       " 'have',\n",
       " 'very',\n",
       " 'healthy',\n",
       " 'master',\n",
       " 'minion',\n",
       " 'relationship',\n",
       " 'hate',\n",
       " 'snake',\n",
       " 'ughhhh',\n",
       " 'freak',\n",
       " 'out',\n",
       " 'n',\n",
       " 'im',\n",
       " 'high',\n",
       " 'hell',\n",
       " 'oooo',\n",
       " 'brother',\n",
       " 'wont',\n",
       " 'turn',\n",
       " 'damn',\n",
       " 'channel',\n",
       " 'im',\n",
       " 'the',\n",
       " 'rm',\n",
       " 'jes_cuh',\n",
       " 'fuhk',\n",
       " 'people',\n",
       " 'totally',\n",
       " 'understand',\n",
       " 'kicking',\n",
       " 'with',\n",
       " 'genesis',\n",
       " 'dramatic',\n",
       " 'watching',\n",
       " 'chick',\n",
       " 'flick',\n",
       " 'is',\n",
       " 'highly',\n",
       " 'entertaining',\n",
       " 'surprisingly',\n",
       " 'jamesheart',\n",
       " 's',\n",
       " 'warm',\n",
       " 'm',\n",
       " 'sitting',\n",
       " 'a',\n",
       " 'room',\n",
       " 'nothing',\n",
       " 'amp',\n",
       " 'm',\n",
       " 'sweating',\n",
       " 'plus',\n",
       " 'miss',\n",
       " 'computer',\n",
       " 'my',\n",
       " 'iphone',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'x',\n",
       " 'oy',\n",
       " 'sleep',\n",
       " 'i',\n",
       " 'fly',\n",
       " 'home',\n",
       " 'tomorrow',\n",
       " 'drs',\n",
       " 'appointment',\n",
       " 'day',\n",
       " 'monday',\n",
       " 'fml',\n",
       " 'quot',\n",
       " 'plasil',\n",
       " 'quot',\n",
       " 'the',\n",
       " 'best',\n",
       " 'vomit',\n",
       " 'stopping',\n",
       " 'medicine',\n",
       " 'there',\n",
       " 'should',\n",
       " 'get',\n",
       " 'of',\n",
       " 'drunkard',\n",
       " 'have',\n",
       " 'few',\n",
       " 'at',\n",
       " 'home',\n",
       " 'hahaha',\n",
       " 's',\n",
       " 'line',\n",
       " 'a',\n",
       " 'song',\n",
       " 'first',\n",
       " 'album',\n",
       " 'describes',\n",
       " 'my',\n",
       " 'tip',\n",
       " 'the',\n",
       " 'night',\n",
       " 'anyone',\n",
       " 'guess',\n",
       " 'line',\n",
       " 'is',\n",
       " 'parking',\n",
       " 'right',\n",
       " 'nfront',\n",
       " 'myinkyfingersau',\n",
       " 'are',\n",
       " 'u',\n",
       " 'getting',\n",
       " 'misha',\n",
       " 'ha',\n",
       " 'twitterfon',\n",
       " 'his',\n",
       " 'iphone',\n",
       " 'wa',\n",
       " 'tweeting',\n",
       " 'his',\n",
       " 'iphone',\n",
       " 'making',\n",
       " 'garlic',\n",
       " 'bread',\n",
       " 'taking',\n",
       " 'longer',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'weekend',\n",
       " 'wa',\n",
       " 'lame',\n",
       " 'i',\n",
       " 'wa',\n",
       " 'work',\n",
       " 'do',\n",
       " 'homework',\n",
       " 'retaann',\n",
       " 'well',\n",
       " 'problem',\n",
       " 'i',\n",
       " 'spent',\n",
       " 'lot',\n",
       " 'money',\n",
       " 'weekend',\n",
       " 'we',\n",
       " 'see',\n",
       " 'feel',\n",
       " 'better',\n",
       " 'thegadgetshow',\n",
       " 'hi',\n",
       " 'you',\n",
       " 'tell',\n",
       " 'john',\n",
       " 'wa',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'getting',\n",
       " 'n',\n",
       " 'i',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'teemwilliams',\n",
       " 'hey',\n",
       " 'michelle',\n",
       " 'u',\n",
       " 'like',\n",
       " 'buy',\n",
       " 'art',\n",
       " 'have',\n",
       " 'art',\n",
       " 'piece',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'sell',\n",
       " 'plz',\n",
       " 'let',\n",
       " 'know',\n",
       " 'interested',\n",
       " 'thnx',\n",
       " 'rainbowsoulpoet',\n",
       " 'thank',\n",
       " 'davidarchie',\n",
       " 'cat',\n",
       " 'annyoing',\n",
       " 'u',\n",
       " 't',\n",
       " 'get',\n",
       " 'rest',\n",
       " 'xoxo',\n",
       " 'sleeping',\n",
       " 'soooon',\n",
       " 'is',\n",
       " 'amp',\n",
       " 'm',\n",
       " 'waking',\n",
       " 'at',\n",
       " 'go',\n",
       " 'to',\n",
       " 'school',\n",
       " 'i',\n",
       " 'pro',\n",
       " 'tonight',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'be',\n",
       " 'soooo',\n",
       " 'great',\n",
       " 'the',\n",
       " 'king',\n",
       " 'hey',\n",
       " 'monday',\n",
       " 'lt',\n",
       " 'quite',\n",
       " 'annoyed',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'stay',\n",
       " 'rosies',\n",
       " 'house',\n",
       " 'though',\n",
       " 'wa',\n",
       " 'excited',\n",
       " 'be',\n",
       " 'home',\n",
       " 'alone',\n",
       " 'chill',\n",
       " 'but',\n",
       " 'i',\n",
       " 'so',\n",
       " 'bored',\n",
       " 'stretchmarkmama',\n",
       " 'wa',\n",
       " 'perfect',\n",
       " 'mahika',\n",
       " 'm',\n",
       " 'of',\n",
       " 'classic',\n",
       " 'historicals',\n",
       " 'political',\n",
       " 'fan',\n",
       " 'do',\n",
       " 'like',\n",
       " 'vampire',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = flatten(data[\"text_processed\"])\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 3329, 'i': 2454, 'a': 2083, 'my': 1476, 'day': 1364, 'm': 1292, 'wa': 1265, 't': 1221, 's': 1184, 'get': 1142, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(flat_list)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dist = {}\n",
    "for key, value in fdist.items():\n",
    "    if key == 'the':\n",
    "        pass\n",
    "    elif len(key) > 2:\n",
    "        new_dist[key]= value\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 838,\n",
       " 'nice': 294,\n",
       " 'home': 477,\n",
       " 'back': 730,\n",
       " 'really': 617,\n",
       " 'want': 632,\n",
       " 'see': 538,\n",
       " 'but': 209,\n",
       " 'dont': 219,\n",
       " 'enough': 84,\n",
       " 'courage': 3,\n",
       " 'scared': 37,\n",
       " 'alone': 56,\n",
       " 'tonight': 320,\n",
       " 'going': 818,\n",
       " 'fucking': 46,\n",
       " 'amazing': 154,\n",
       " 'aholston': 1,\n",
       " 'aww': 117,\n",
       " 'hope': 445,\n",
       " 'get': 1142,\n",
       " 'everything': 108,\n",
       " 'done': 187,\n",
       " 'aaronklein': 1,\n",
       " 'mchesner': 1,\n",
       " 'artist': 10,\n",
       " 'type': 22,\n",
       " 'resist': 4,\n",
       " 'jab': 3,\n",
       " 'good': 1129,\n",
       " 'morning': 496,\n",
       " 'everyone': 197,\n",
       " 'ready': 172,\n",
       " 'start': 167,\n",
       " 'another': 185,\n",
       " 'exciting': 16,\n",
       " 'week': 338,\n",
       " 'degree': 18,\n",
       " 'outside': 83,\n",
       " 'net': 18,\n",
       " 'hme': 1,\n",
       " 'rbflygal': 1,\n",
       " 'bridal': 1,\n",
       " 'shower': 65,\n",
       " 'without': 113,\n",
       " 'sex': 27,\n",
       " 'toy': 15,\n",
       " 'uni': 19,\n",
       " 'work': 860,\n",
       " 'wish': 419,\n",
       " 'luck': 116,\n",
       " 'thisisdavina': 5,\n",
       " 'awesome': 230,\n",
       " 'ack': 2,\n",
       " 'sure': 181,\n",
       " 'mum': 46,\n",
       " 'bought': 50,\n",
       " 'workout': 27,\n",
       " 'swear': 12,\n",
       " 'never': 221,\n",
       " 'stop': 97,\n",
       " 'complaining': 4,\n",
       " 'still': 531,\n",
       " 'doe': 124,\n",
       " 'rosyantoine': 1,\n",
       " 'shayboo': 1,\n",
       " 'lyfe': 1,\n",
       " 'yeah': 281,\n",
       " 'meeting': 32,\n",
       " 'july': 39,\n",
       " 'wonder': 32,\n",
       " 'whether': 6,\n",
       " 'fukuoka': 1,\n",
       " 'knew': 26,\n",
       " 'iata': 1,\n",
       " 'code': 14,\n",
       " 'fuk': 2,\n",
       " 'two': 112,\n",
       " 'day': 1364,\n",
       " 'till': 84,\n",
       " 'leave': 84,\n",
       " 'today': 825,\n",
       " 'seems': 58,\n",
       " 'like': 957,\n",
       " 'either': 68,\n",
       " 'buy': 89,\n",
       " 'shoe': 34,\n",
       " 'make': 438,\n",
       " 'print': 4,\n",
       " 'talk': 111,\n",
       " 'business': 22,\n",
       " 'happens': 26,\n",
       " 'whoop': 15,\n",
       " 'phone': 179,\n",
       " 'call': 126,\n",
       " 'dinner': 109,\n",
       " 'nearly': 25,\n",
       " 'forgotten': 15,\n",
       " 'not': 442,\n",
       " 'time': 829,\n",
       " 'stupid': 95,\n",
       " 'emmmmm': 2,\n",
       " 'someone': 165,\n",
       " 'clever': 6,\n",
       " 'using': 57,\n",
       " 'twitter': 448,\n",
       " 'their': 53,\n",
       " 'lol': 737,\n",
       " 'were': 92,\n",
       " 'comp': 11,\n",
       " 'soooo': 42,\n",
       " 'boring': 59,\n",
       " 'pauljmcmahon': 1,\n",
       " 'decided': 26,\n",
       " 'turn': 58,\n",
       " 'sky': 21,\n",
       " 'summer': 161,\n",
       " 'nope': 33,\n",
       " 'stuck': 52,\n",
       " 'now': 224,\n",
       " 'anyone': 96,\n",
       " 'following': 70,\n",
       " 'please': 192,\n",
       " 'follow': 159,\n",
       " 'well': 582,\n",
       " 'otherwise': 16,\n",
       " 'will': 305,\n",
       " 'deleted': 17,\n",
       " 'miss': 465,\n",
       " 'midshorelife': 1,\n",
       " 'our': 89,\n",
       " 'service': 27,\n",
       " 'about': 128,\n",
       " 'farmer': 8,\n",
       " 'market': 15,\n",
       " 'watching': 285,\n",
       " 'quot': 893,\n",
       " 'lucky': 54,\n",
       " 'one': 743,\n",
       " 'need': 556,\n",
       " 'movie': 192,\n",
       " 'buddy': 29,\n",
       " 'wetaworkshop': 1,\n",
       " 'bank': 18,\n",
       " 'holiday': 55,\n",
       " 'weekend': 262,\n",
       " 'lose': 28,\n",
       " 'shiftywooten': 1,\n",
       " 'who': 24,\n",
       " 'know': 667,\n",
       " 'sadly': 31,\n",
       " 'doing': 76,\n",
       " 'houston': 15,\n",
       " 'eringo_braless': 1,\n",
       " 'can': 560,\n",
       " 'web': 24,\n",
       " 'way': 310,\n",
       " 'damn': 161,\n",
       " 'game': 165,\n",
       " 'just': 459,\n",
       " 'might': 127,\n",
       " 'lebron': 10,\n",
       " 'knicks': 2,\n",
       " 'jersey': 13,\n",
       " 'next': 246,\n",
       " 'year': 218,\n",
       " 'sitting': 65,\n",
       " 'and': 380,\n",
       " 'feeling': 232,\n",
       " 'sad': 363,\n",
       " 'broke': 49,\n",
       " 'with': 215,\n",
       " 'boyfriend': 26,\n",
       " 'single': 18,\n",
       " 'dear': 37,\n",
       " 'wetzels': 1,\n",
       " 'pretzel': 1,\n",
       " 'dog': 86,\n",
       " 'you': 1107,\n",
       " 'auntie': 3,\n",
       " 'anne': 2,\n",
       " 'cash': 8,\n",
       " 'only': 129,\n",
       " 'hillsong': 4,\n",
       " 'tom': 29,\n",
       " 'night': 561,\n",
       " 'dad': 78,\n",
       " 'birthday': 129,\n",
       " 'could': 257,\n",
       " 'bday': 31,\n",
       " 'though': 308,\n",
       " 'anonymouspinay': 1,\n",
       " 'had': 295,\n",
       " 'place': 96,\n",
       " 'let': 209,\n",
       " 'walk': 65,\n",
       " 'around': 119,\n",
       " 'naked': 8,\n",
       " 'queenclariss': 1,\n",
       " 'idk': 30,\n",
       " 'sent': 31,\n",
       " 'message': 40,\n",
       " 'came': 54,\n",
       " 'registered': 5,\n",
       " 'imma': 14,\n",
       " 'lay': 14,\n",
       " 'watch': 188,\n",
       " 'head': 136,\n",
       " 'killin': 4,\n",
       " 'area': 10,\n",
       " 'due': 34,\n",
       " 'schedule': 16,\n",
       " 'able': 45,\n",
       " 'hang': 47,\n",
       " 'people': 243,\n",
       " 'happy': 328,\n",
       " 'leona': 2,\n",
       " 'lewis': 5,\n",
       " 'tour': 48,\n",
       " 'catch': 35,\n",
       " 'drift': 1,\n",
       " 'have': 876,\n",
       " 'withdrawn': 1,\n",
       " 'spice': 3,\n",
       " 'range': 5,\n",
       " 'product': 16,\n",
       " 'further': 2,\n",
       " 'notice': 15,\n",
       " 'government': 4,\n",
       " 'wrongly': 1,\n",
       " 'belief': 3,\n",
       " 'illegal': 2,\n",
       " 'snicker': 4,\n",
       " 'king': 19,\n",
       " 'sized': 1,\n",
       " 'broken': 42,\n",
       " 'ugh': 143,\n",
       " 'omarion': 1,\n",
       " 'sooooo': 19,\n",
       " 'called': 51,\n",
       " 'tape': 8,\n",
       " 'public': 16,\n",
       " 'figured': 12,\n",
       " 'ask': 52,\n",
       " 'star': 43,\n",
       " 'sick': 199,\n",
       " 'cold': 111,\n",
       " 'zack': 3,\n",
       " 'efron': 4,\n",
       " 'top': 48,\n",
       " 'billing': 2,\n",
       " 'matthew': 3,\n",
       " 'perry': 3,\n",
       " 'iamthecommodore': 3,\n",
       " 'hot': 140,\n",
       " 'agreat': 1,\n",
       " 'run': 81,\n",
       " 'detroit': 6,\n",
       " 'win': 96,\n",
       " 'buckhollywood': 3,\n",
       " 'city': 43,\n",
       " 'amp': 601,\n",
       " 'rewatching': 2,\n",
       " 'season': 75,\n",
       " 'show': 203,\n",
       " 'eat': 75,\n",
       " 'aunt': 17,\n",
       " 'soooon': 4,\n",
       " 'getting': 288,\n",
       " 'changing': 8,\n",
       " 'goood': 8,\n",
       " 'miissss': 1,\n",
       " 'himm': 1,\n",
       " 'omg': 153,\n",
       " 'hanadi': 1,\n",
       " 'abusing': 1,\n",
       " 'mayonice': 1,\n",
       " 'goodness': 21,\n",
       " 'wondering': 28,\n",
       " 'hell': 65,\n",
       " 'girl': 200,\n",
       " 'publish': 2,\n",
       " 'name': 84,\n",
       " 'poor': 112,\n",
       " 'thing': 325,\n",
       " 'rockergirl': 1,\n",
       " 'joeymcintyre': 8,\n",
       " 'tendency': 1,\n",
       " 'stick': 23,\n",
       " 'long': 190,\n",
       " 'tease': 2,\n",
       " 'tjinkerson': 1,\n",
       " 'those': 57,\n",
       " 'include': 10,\n",
       " 'catherinecas': 1,\n",
       " 'also': 117,\n",
       " 'play': 131,\n",
       " 'tongits': 2,\n",
       " 'your': 275,\n",
       " 'mac': 45,\n",
       " 'download': 33,\n",
       " 'enjoy': 94,\n",
       " 'currently': 23,\n",
       " 'trying': 145,\n",
       " 'figure': 38,\n",
       " 'where': 29,\n",
       " 'fuck': 68,\n",
       " 'went': 172,\n",
       " 'adorable': 16,\n",
       " 'class': 98,\n",
       " 'off': 79,\n",
       " 'train': 65,\n",
       " 'station': 14,\n",
       " 'boa': 2,\n",
       " 'noite': 1,\n",
       " 'follower': 118,\n",
       " 'weeelady': 1,\n",
       " 'uncle': 8,\n",
       " 'bunch': 26,\n",
       " 'running': 49,\n",
       " 'rubbing': 2,\n",
       " 'eye': 82,\n",
       " 'hay': 9,\n",
       " 'fever': 21,\n",
       " 'singing': 30,\n",
       " 'rather': 38,\n",
       " 'tunlessly': 1,\n",
       " 'arctic': 1,\n",
       " 'monkey': 8,\n",
       " 'wasted': 5,\n",
       " 'saterday': 1,\n",
       " 'jordanknight': 18,\n",
       " 'shit': 95,\n",
       " 'would': 339,\n",
       " 'crazy': 70,\n",
       " 'that': 471,\n",
       " 'real': 74,\n",
       " 'reason': 70,\n",
       " 'technical': 3,\n",
       " 'difficulty': 2,\n",
       " 'olliandlime': 1,\n",
       " 'lurve': 2,\n",
       " 'esp': 9,\n",
       " 'red': 58,\n",
       " 'waiting': 99,\n",
       " 'boot': 12,\n",
       " 'arrive': 6,\n",
       " 'hoof': 1,\n",
       " 'feed': 17,\n",
       " 'daughter': 32,\n",
       " 'fetish': 1,\n",
       " 'mileycyrus': 62,\n",
       " 'wdw': 3,\n",
       " 'hannah': 20,\n",
       " 'laptop': 47,\n",
       " 'cant': 212,\n",
       " 'wait': 260,\n",
       " 'bluray': 2,\n",
       " 'mornin': 13,\n",
       " 'tweetie': 10,\n",
       " 'pie': 9,\n",
       " 'salon': 4,\n",
       " 'great': 443,\n",
       " 'flexible': 4,\n",
       " 'job': 140,\n",
       " 'cancerscore': 1,\n",
       " 'course': 69,\n",
       " 'moving': 30,\n",
       " 'always': 195,\n",
       " 'stressful': 7,\n",
       " 'anything': 86,\n",
       " 'help': 180,\n",
       " 'new': 518,\n",
       " 'house': 168,\n",
       " 'yay': 137,\n",
       " 'ijustine': 2,\n",
       " 'for': 303,\n",
       " 'outstanding': 3,\n",
       " 'key': 19,\n",
       " 'word': 69,\n",
       " 'astridnonikpp': 1,\n",
       " 'understand': 38,\n",
       " 'aight': 2,\n",
       " 'burnt': 23,\n",
       " 'from': 60,\n",
       " 'take': 256,\n",
       " 'pizza': 30,\n",
       " 'outta': 23,\n",
       " 'tha': 16,\n",
       " 'oven': 5,\n",
       " 'wasnt': 27,\n",
       " 'even': 239,\n",
       " 'pau': 1,\n",
       " 'haw': 1,\n",
       " 'mayyyun': 1,\n",
       " 'used': 66,\n",
       " 'ghd': 1,\n",
       " 'straightner': 1,\n",
       " 'half': 76,\n",
       " 'better': 286,\n",
       " 'somee': 1,\n",
       " 'food': 115,\n",
       " 'feel': 470,\n",
       " 'fat': 27,\n",
       " 'ashleymelchert': 1,\n",
       " 'haha': 374,\n",
       " 'cool': 180,\n",
       " 'bean': 13,\n",
       " 'together': 48,\n",
       " 'akkkkk': 1,\n",
       " 'haven': 58,\n",
       " 'they': 148,\n",
       " 'invented': 1,\n",
       " 'teleporting': 1,\n",
       " 'booooo': 4,\n",
       " 'tweetlord': 1,\n",
       " 'role': 7,\n",
       " 'playing': 89,\n",
       " 'check': 122,\n",
       " 'avatar': 13,\n",
       " 'funky': 2,\n",
       " 'item': 8,\n",
       " 'tlgame': 1,\n",
       " 'amazoe': 1,\n",
       " 'hear': 133,\n",
       " 'too': 254,\n",
       " 'more': 149,\n",
       " 'community': 5,\n",
       " 'stuff': 120,\n",
       " 'travel': 10,\n",
       " 'don': 305,\n",
       " 'wan': 216,\n",
       " 'chicago': 21,\n",
       " 'update': 85,\n",
       " 'learn': 34,\n",
       " 'hoedown': 2,\n",
       " 'throwdown': 2,\n",
       " 'joystick': 1,\n",
       " 'copy': 29,\n",
       " 'flight': 45,\n",
       " 'simulator': 1,\n",
       " 'window': 45,\n",
       " 'fly': 34,\n",
       " 'peanut': 12,\n",
       " 'butter': 12,\n",
       " 'brownie': 7,\n",
       " 'blueberry': 4,\n",
       " 'bagel': 4,\n",
       " 'chocolate': 44,\n",
       " 'ginger': 2,\n",
       " 'crisp': 3,\n",
       " 'oatmeal': 1,\n",
       " 'icecream': 4,\n",
       " 'yes': 255,\n",
       " 'papercakes': 3,\n",
       " 'snow': 28,\n",
       " 'keep': 172,\n",
       " 'border': 6,\n",
       " 'this': 318,\n",
       " 'weather': 155,\n",
       " 'changed': 23,\n",
       " 'background': 21,\n",
       " 'picture': 98,\n",
       " 'dehfamsincere': 1,\n",
       " 'tired': 188,\n",
       " 'tweats': 1,\n",
       " 'thenolookpass': 2,\n",
       " 'english': 43,\n",
       " 'professor': 1,\n",
       " 'late': 99,\n",
       " 'submission': 1,\n",
       " 'totally': 94,\n",
       " 'fine': 57,\n",
       " 'add': 62,\n",
       " 'tomorrow': 438,\n",
       " 'nocturnalie': 1,\n",
       " 'anyway': 52,\n",
       " 'abby': 4,\n",
       " 'share': 28,\n",
       " 'crop': 1,\n",
       " 'very': 108,\n",
       " 'healthy': 14,\n",
       " 'master': 7,\n",
       " 'minion': 3,\n",
       " 'relationship': 6,\n",
       " 'hate': 303,\n",
       " 'snake': 4,\n",
       " 'ughhhh': 5,\n",
       " 'freak': 13,\n",
       " 'out': 166,\n",
       " 'high': 54,\n",
       " 'oooo': 2,\n",
       " 'brother': 87,\n",
       " 'wont': 42,\n",
       " 'channel': 22,\n",
       " 'jes_cuh': 1,\n",
       " 'fuhk': 1,\n",
       " 'kicking': 12,\n",
       " 'genesis': 2,\n",
       " 'dramatic': 2,\n",
       " 'chick': 16,\n",
       " 'flick': 6,\n",
       " 'highly': 10,\n",
       " 'entertaining': 11,\n",
       " 'surprisingly': 7,\n",
       " 'jamesheart': 1,\n",
       " 'warm': 30,\n",
       " 'room': 79,\n",
       " 'nothing': 157,\n",
       " 'sweating': 4,\n",
       " 'plus': 38,\n",
       " 'computer': 71,\n",
       " 'iphone': 89,\n",
       " 'moment': 59,\n",
       " 'sleep': 328,\n",
       " 'drs': 2,\n",
       " 'appointment': 9,\n",
       " 'monday': 118,\n",
       " 'fml': 27,\n",
       " 'plasil': 1,\n",
       " 'best': 239,\n",
       " 'vomit': 2,\n",
       " 'stopping': 7,\n",
       " 'medicine': 7,\n",
       " 'there': 209,\n",
       " 'should': 159,\n",
       " 'drunkard': 1,\n",
       " 'few': 41,\n",
       " 'hahaha': 86,\n",
       " 'line': 48,\n",
       " 'song': 159,\n",
       " 'first': 203,\n",
       " 'album': 60,\n",
       " 'describes': 2,\n",
       " 'tip': 19,\n",
       " 'guess': 140,\n",
       " 'parking': 7,\n",
       " 'right': 306,\n",
       " 'nfront': 1,\n",
       " 'myinkyfingersau': 1,\n",
       " 'are': 418,\n",
       " 'misha': 2,\n",
       " 'twitterfon': 5,\n",
       " 'his': 91,\n",
       " 'tweeting': 37,\n",
       " 'making': 103,\n",
       " 'garlic': 4,\n",
       " 'bread': 12,\n",
       " 'taking': 71,\n",
       " 'longer': 35,\n",
       " 'lame': 24,\n",
       " 'homework': 49,\n",
       " 'retaann': 1,\n",
       " 'problem': 73,\n",
       " 'spent': 31,\n",
       " 'lot': 197,\n",
       " 'money': 90,\n",
       " 'thegadgetshow': 2,\n",
       " 'tell': 137,\n",
       " 'john': 25,\n",
       " 'looking': 209,\n",
       " 'forward': 108,\n",
       " 'teemwilliams': 2,\n",
       " 'hey': 224,\n",
       " 'michelle': 5,\n",
       " 'art': 26,\n",
       " 'piece': 20,\n",
       " 'sell': 20,\n",
       " 'plz': 21,\n",
       " 'interested': 14,\n",
       " 'thnx': 8,\n",
       " 'rainbowsoulpoet': 1,\n",
       " 'thank': 230,\n",
       " 'davidarchie': 16,\n",
       " 'cat': 58,\n",
       " 'annyoing': 1,\n",
       " 'rest': 70,\n",
       " 'xoxo': 36,\n",
       " 'sleeping': 48,\n",
       " 'waking': 32,\n",
       " 'school': 243,\n",
       " 'pro': 15,\n",
       " 'gon': 301,\n",
       " 'quite': 66,\n",
       " 'annoyed': 18,\n",
       " 'stay': 106,\n",
       " 'rosies': 1,\n",
       " 'excited': 117,\n",
       " 'chill': 22,\n",
       " 'bored': 133,\n",
       " 'stretchmarkmama': 1,\n",
       " 'perfect': 43,\n",
       " 'mahika': 1,\n",
       " 'classic': 8,\n",
       " 'historicals': 2,\n",
       " 'political': 1,\n",
       " 'fan': 84,\n",
       " 'vampire': 7,\n",
       " 'book': 98,\n",
       " 'depends': 8,\n",
       " 'jaredleto': 2,\n",
       " 'think': 551,\n",
       " 'pool': 47,\n",
       " 'video': 128,\n",
       " 'n_n': 1,\n",
       " 'kthanks': 2,\n",
       " 'torture': 6,\n",
       " 'vegetarian': 3,\n",
       " 'fish': 20,\n",
       " 'gut': 5,\n",
       " 'sink': 4,\n",
       " 'except': 34,\n",
       " 'already': 168,\n",
       " 'shaundiviney': 9,\n",
       " 'boo': 67,\n",
       " 'doin': 23,\n",
       " 'meet': 76,\n",
       " 'sat': 36,\n",
       " 'likely': 11,\n",
       " 'member': 17,\n",
       " 'blonde': 9,\n",
       " 'got': 872,\n",
       " 'bessemerprocess': 1,\n",
       " 'dani': 2,\n",
       " 'charlie': 3,\n",
       " 'ted': 3,\n",
       " 'all': 410,\n",
       " 'character': 16,\n",
       " 'finished': 101,\n",
       " 'biking': 3,\n",
       " 'lopez': 2,\n",
       " 'island': 12,\n",
       " 'laying': 15,\n",
       " 'bex_smith': 1,\n",
       " 'becky': 2,\n",
       " 'watchh': 1,\n",
       " 'thisss': 2,\n",
       " 'hollowbabes': 1,\n",
       " 'tory': 1,\n",
       " 'alternative': 6,\n",
       " 'any': 51,\n",
       " 'kennethcold': 1,\n",
       " 'forgot': 76,\n",
       " 'give': 107,\n",
       " 'camera': 27,\n",
       " 'baby': 133,\n",
       " 'oli': 2,\n",
       " 'sykes': 2,\n",
       " 'ugly': 17,\n",
       " 'look': 285,\n",
       " 'man': 184,\n",
       " 'mean': 143,\n",
       " 'dude': 49,\n",
       " 'nell_xo': 1,\n",
       " 'mpgatbluefly': 1,\n",
       " 'awwww': 12,\n",
       " 'aoption': 1,\n",
       " 'plan': 60,\n",
       " 'save': 36,\n",
       " 'future': 28,\n",
       " 'trip': 70,\n",
       " 'since': 102,\n",
       " 'afford': 19,\n",
       " 'live': 134,\n",
       " 'america': 20,\n",
       " 'most': 33,\n",
       " 'european': 6,\n",
       " 'sbittie': 1,\n",
       " 'saw': 116,\n",
       " 'stackszs': 1,\n",
       " 'noo': 6,\n",
       " 'isnt': 32,\n",
       " 'store': 42,\n",
       " 'left': 125,\n",
       " 'min': 68,\n",
       " 'earlier': 37,\n",
       " 'talking': 63,\n",
       " 'friend': 309,\n",
       " 'mistresspolly': 1,\n",
       " 'indeed': 15,\n",
       " 'some': 205,\n",
       " 'yummy': 23,\n",
       " 'isn': 23,\n",
       " 'hallmark': 1,\n",
       " 'zenrhe': 1,\n",
       " 'grown': 7,\n",
       " 'fond': 2,\n",
       " 'tweet': 211,\n",
       " 'deck': 7,\n",
       " 'group': 16,\n",
       " 'panel': 3,\n",
       " 'katiemacalister': 1,\n",
       " 'ooh': 22,\n",
       " 'liking': 13,\n",
       " 'marius': 1,\n",
       " 'him': 54,\n",
       " 'spamming': 3,\n",
       " 'bradiewebb': 10,\n",
       " 'missed': 127,\n",
       " 'mall': 29,\n",
       " 'news': 83,\n",
       " 'married': 14,\n",
       " 'ughh': 17,\n",
       " 'questlove': 1,\n",
       " 'promise': 16,\n",
       " 'every': 88,\n",
       " 'random': 21,\n",
       " 'fluid': 4,\n",
       " 'princesssuperc': 3,\n",
       " 'both': 28,\n",
       " 'rock': 59,\n",
       " 'ashleytisdale': 3,\n",
       " 'gosh': 27,\n",
       " 'scary': 24,\n",
       " 'hotel': 17,\n",
       " 'paris': 14,\n",
       " 'djjmytaco': 1,\n",
       " 'ewwww': 3,\n",
       " 'aint': 24,\n",
       " 'munkimatt': 1,\n",
       " 'what': 142,\n",
       " 'abt': 12,\n",
       " 'facebook': 55,\n",
       " 'friending': 1,\n",
       " 'hannamanna': 1,\n",
       " 'push': 8,\n",
       " 'blue': 34,\n",
       " 'festival': 19,\n",
       " 'broadbeach': 2,\n",
       " 'bit': 153,\n",
       " 'office': 67,\n",
       " 'thorsten': 1,\n",
       " 'online': 69,\n",
       " 'yet': 184,\n",
       " 'much': 447,\n",
       " 'hmm': 46,\n",
       " 'bill': 25,\n",
       " 'beat': 31,\n",
       " 'maybedaisies': 1,\n",
       " 'lovellyy': 1,\n",
       " 'saddddddd': 1,\n",
       " 'sunshine': 44,\n",
       " 'laters': 4,\n",
       " 'goin': 45,\n",
       " 'doctorrrrr': 1,\n",
       " 'wolfarm_alpha': 1,\n",
       " 'gdp': 1,\n",
       " 'china': 9,\n",
       " 'snapshop': 1,\n",
       " 'kee': 2,\n",
       " 'comparing': 1,\n",
       " 'usa': 9,\n",
       " 'considering': 10,\n",
       " 'super': 82,\n",
       " 'final': 66,\n",
       " 'dance': 48,\n",
       " 'reheaserals': 1,\n",
       " 'lunalupin': 1,\n",
       " 'ahhh': 34,\n",
       " 'okay': 75,\n",
       " 'she': 118,\n",
       " 'free': 99,\n",
       " 'yoitsandrea': 1,\n",
       " 'difference': 16,\n",
       " 'fun': 346,\n",
       " 'thinking': 104,\n",
       " 'funny': 96,\n",
       " 'sorry': 342,\n",
       " 'hammer': 5,\n",
       " 'stumbleupon': 1,\n",
       " 'down': 55,\n",
       " 'may': 114,\n",
       " 'dreamin': 1,\n",
       " 'loud': 18,\n",
       " 'mine': 80,\n",
       " 'afternoon': 55,\n",
       " 'jodymal': 1,\n",
       " 'tamaraschilling': 1,\n",
       " 'thought': 153,\n",
       " 'everybody': 26,\n",
       " 'callumstacy': 1,\n",
       " 'dream': 83,\n",
       " 'york': 14,\n",
       " 'wyelin': 1,\n",
       " 'groupie': 1,\n",
       " 'whoever': 5,\n",
       " 'ayu': 1,\n",
       " 'pop': 24,\n",
       " 'pretty': 140,\n",
       " 'lazy': 45,\n",
       " 'unfortunately': 41,\n",
       " 'overcast': 5,\n",
       " 'chilly': 7,\n",
       " 'mariahbaker': 1,\n",
       " 'mzahmad': 1,\n",
       " 'last': 433,\n",
       " 'housekeeper': 1,\n",
       " 'turned': 27,\n",
       " 'chore': 7,\n",
       " 'marsherlin': 1,\n",
       " 'dagupan': 1,\n",
       " 'enrollment': 1,\n",
       " 'baguio': 1,\n",
       " 'flybymusic': 1,\n",
       " 'thats': 118,\n",
       " 'blame': 16,\n",
       " 'favee': 1,\n",
       " 'masturbation': 2,\n",
       " 'trick': 8,\n",
       " 'princesscrys': 1,\n",
       " 'kidddingg': 1,\n",
       " 'thereeee': 1,\n",
       " 'ermadea': 1,\n",
       " 'deal': 23,\n",
       " 'quick': 23,\n",
       " 'trash': 7,\n",
       " 'multiple': 8,\n",
       " 'msg': 7,\n",
       " 'direct': 9,\n",
       " 'pager': 1,\n",
       " 'past': 42,\n",
       " 'retrieving': 1,\n",
       " 'cooking': 14,\n",
       " 'lunch': 88,\n",
       " 'alive': 11,\n",
       " 'painfull': 2,\n",
       " 'hand': 66,\n",
       " 'burn': 18,\n",
       " 'mention': 24,\n",
       " 'drink': 74,\n",
       " 'view': 22,\n",
       " 'whoopi': 1,\n",
       " 'nuff': 2,\n",
       " 'busy': 77,\n",
       " 'family': 97,\n",
       " 'later': 122,\n",
       " 'evening': 44,\n",
       " 'heart': 61,\n",
       " 'jon': 31,\n",
       " 'kate': 27,\n",
       " 'gosslin': 1,\n",
       " 'divorce': 4,\n",
       " 'soooooo': 7,\n",
       " 'brainpicker': 1,\n",
       " 'led': 4,\n",
       " 'beautiful': 108,\n",
       " 'connection': 22,\n",
       " 'project': 33,\n",
       " 'nokia': 3,\n",
       " 'point': 45,\n",
       " 'flash': 11,\n",
       " 'valid': 3,\n",
       " 'glad': 135,\n",
       " 'appreciated': 13,\n",
       " 'generally': 4,\n",
       " 'jealous': 47,\n",
       " 'doesn': 46,\n",
       " 'study': 49,\n",
       " 'mrcheater': 1,\n",
       " 'wow': 157,\n",
       " 'cleaned': 6,\n",
       " 'aquarium': 1,\n",
       " 'bianca': 2,\n",
       " 'regularly': 4,\n",
       " 'sing': 24,\n",
       " 'guy': 249,\n",
       " 'fast': 35,\n",
       " 'ive': 42,\n",
       " 'london': 44,\n",
       " 'aevans': 1,\n",
       " 'goodnight': 75,\n",
       " 'ieatstuff': 1,\n",
       " 'felly': 1,\n",
       " 'found': 114,\n",
       " 'lost': 167,\n",
       " 'itouch': 1,\n",
       " 'sun': 133,\n",
       " 'pitch': 2,\n",
       " 'black': 43,\n",
       " 'jocelynchu': 1,\n",
       " 'repost': 5,\n",
       " 'founder': 3,\n",
       " 'president': 10,\n",
       " 'eric': 5,\n",
       " 'fonoimoana': 1,\n",
       " 'raining': 58,\n",
       " 'entire': 14,\n",
       " 'nap': 55,\n",
       " 'idea': 104,\n",
       " 'camping': 11,\n",
       " 'ought': 1,\n",
       " 'blogshops': 1,\n",
       " 'pleaseee': 3,\n",
       " 'knowing': 13,\n",
       " 'missing': 90,\n",
       " 'air': 48,\n",
       " 'france': 27,\n",
       " 'plane': 31,\n",
       " 'awful': 24,\n",
       " 'shad': 2,\n",
       " 'wee': 8,\n",
       " 'alamo': 1,\n",
       " 'draft': 3,\n",
       " 'wife': 29,\n",
       " 'smell': 21,\n",
       " 'digestive': 1,\n",
       " 'biscuit': 5,\n",
       " 'foolish': 3,\n",
       " 'fake': 17,\n",
       " 'tan': 23,\n",
       " 'dha': 1,\n",
       " 'pypur': 1,\n",
       " 'jeannebehr': 1,\n",
       " 'took': 69,\n",
       " 'delivery': 7,\n",
       " 'couple': 57,\n",
       " 'hour': 263,\n",
       " 'charge': 12,\n",
       " 'sync': 3,\n",
       " 'use': 117,\n",
       " 'elle_ee_ai_norr': 1,\n",
       " 'hahahahahahaha': 1,\n",
       " 'caplocks': 1,\n",
       " 'wuld': 2,\n",
       " 'strike': 9,\n",
       " 'again': 69,\n",
       " 'nithinkd': 1,\n",
       " 'yesterday': 123,\n",
       " 'coach': 7,\n",
       " 'carter': 1,\n",
       " 'kimbo': 1,\n",
       " 'light': 40,\n",
       " 'account': 36,\n",
       " 'nabaztag': 1,\n",
       " 'didn': 133,\n",
       " 'hooked': 3,\n",
       " 'thedebbyryan': 2,\n",
       " 'bruno': 7,\n",
       " 'trailer': 13,\n",
       " 'caazzzz': 1,\n",
       " 'cazz': 1,\n",
       " 'oooh': 10,\n",
       " 'kinda': 64,\n",
       " 'sweet': 82,\n",
       " 'mxokreis': 1,\n",
       " 'prob': 16,\n",
       " 'frustrated': 11,\n",
       " 'jonasbrothers': 26,\n",
       " 'katie': 12,\n",
       " 'four': 21,\n",
       " 'sushi': 12,\n",
       " 'sue': 2,\n",
       " 'wild': 6,\n",
       " 'amazon': 5,\n",
       " 'adventure': 10,\n",
       " 'firienbarn': 1,\n",
       " 'reply': 67,\n",
       " 'typing': 7,\n",
       " 'emilysmum': 1,\n",
       " 'clicking': 5,\n",
       " 'arrow': 1,\n",
       " 'put': 117,\n",
       " 'mouse': 11,\n",
       " 'spending': 15,\n",
       " 'warren': 3,\n",
       " 'til': 52,\n",
       " 'sunday': 129,\n",
       " 'longest': 7,\n",
       " 'ever': 184,\n",
       " 'cripes': 1,\n",
       " 'oil': 9,\n",
       " 'tank': 4,\n",
       " 'upcoming': 2,\n",
       " 'zorels': 1,\n",
       " 'asma': 1,\n",
       " 'yan': 1,\n",
       " 'seludup': 1,\n",
       " 'masuk': 1,\n",
       " 'pringles': 2,\n",
       " 'body': 36,\n",
       " 'aching': 4,\n",
       " 'power': 35,\n",
       " 'zzz': 5,\n",
       " 'rested': 1,\n",
       " 'tweetdeck': 29,\n",
       " 'starting': 59,\n",
       " 'taskbar': 1,\n",
       " 'vista': 7,\n",
       " 'closing': 10,\n",
       " 'fix': 27,\n",
       " 'issue': 20,\n",
       " 'cairokate': 1,\n",
       " 'find': 191,\n",
       " 'attend': 12,\n",
       " 'webinar': 1,\n",
       " 'social': 17,\n",
       " 'medium': 18,\n",
       " 'strategy': 3,\n",
       " 'how': 99,\n",
       " 'successful': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 1364,\n",
       " 'get': 1142,\n",
       " 'good': 1129,\n",
       " 'you': 1107,\n",
       " 'like': 957,\n",
       " 'quot': 893,\n",
       " 'have': 876,\n",
       " 'got': 872,\n",
       " 'work': 860,\n",
       " 'love': 838,\n",
       " 'time': 829,\n",
       " 'today': 825,\n",
       " 'going': 818,\n",
       " 'one': 743,\n",
       " 'lol': 737,\n",
       " 'back': 730,\n",
       " 'know': 667,\n",
       " 'want': 632,\n",
       " 'really': 617,\n",
       " 'amp': 601,\n",
       " 'well': 582,\n",
       " 'night': 561,\n",
       " 'can': 560,\n",
       " 'need': 556,\n",
       " 'think': 551,\n",
       " 'see': 538,\n",
       " 'still': 531,\n",
       " 'new': 518,\n",
       " 'morning': 496,\n",
       " 'thanks': 490,\n",
       " 'home': 477,\n",
       " 'that': 471,\n",
       " 'feel': 470,\n",
       " 'miss': 465,\n",
       " 'just': 459,\n",
       " 'twitter': 448,\n",
       " 'much': 447,\n",
       " 'hope': 445,\n",
       " 'great': 443,\n",
       " 'not': 442,\n",
       " 'make': 438,\n",
       " 'tomorrow': 438,\n",
       " 'last': 433,\n",
       " 'wish': 419,\n",
       " 'are': 418,\n",
       " 'all': 410,\n",
       " 'and': 380,\n",
       " 'haha': 374,\n",
       " 'sad': 363,\n",
       " 'bad': 349,\n",
       " 'fun': 346,\n",
       " 'sorry': 342,\n",
       " 'would': 339,\n",
       " 'week': 338,\n",
       " 'come': 334,\n",
       " 'happy': 328,\n",
       " 'sleep': 328,\n",
       " 'thing': 325,\n",
       " 'tonight': 320,\n",
       " 'this': 318,\n",
       " 'way': 310,\n",
       " 'friend': 309,\n",
       " 'though': 308,\n",
       " 'right': 306,\n",
       " 'will': 305,\n",
       " 'don': 305,\n",
       " 'for': 303,\n",
       " 'hate': 303,\n",
       " 'gon': 301,\n",
       " 'had': 295,\n",
       " 'nice': 294,\n",
       " 'getting': 288,\n",
       " 'better': 286,\n",
       " 'watching': 285,\n",
       " 'look': 285,\n",
       " 'say': 283,\n",
       " 'yeah': 281,\n",
       " 'your': 275,\n",
       " 'hour': 263,\n",
       " 'weekend': 262,\n",
       " 'wait': 260,\n",
       " 'could': 257,\n",
       " 'take': 256,\n",
       " 'bed': 256,\n",
       " 'yes': 255,\n",
       " 'too': 254,\n",
       " 'guy': 249,\n",
       " 'next': 246,\n",
       " 'people': 243,\n",
       " 'school': 243,\n",
       " 'even': 239,\n",
       " 'best': 239,\n",
       " 'feeling': 232,\n",
       " 'awesome': 230,\n",
       " 'thank': 230,\n",
       " 'now': 224,\n",
       " 'hey': 224,\n",
       " 'never': 221,\n",
       " 'dont': 219,\n",
       " 'working': 219,\n",
       " 'year': 218,\n",
       " 'wan': 216,\n",
       " 'with': 215,\n",
       " 'cant': 212,\n",
       " 'tweet': 211,\n",
       " 'but': 209,\n",
       " 'let': 209,\n",
       " 'there': 209,\n",
       " 'looking': 209,\n",
       " 'little': 209,\n",
       " 'life': 207,\n",
       " 'some': 205,\n",
       " 'show': 203,\n",
       " 'first': 203,\n",
       " 'girl': 200,\n",
       " 'sick': 199,\n",
       " 'everyone': 197,\n",
       " 'lot': 197,\n",
       " 'suck': 196,\n",
       " 'always': 195,\n",
       " 'soon': 195,\n",
       " 'please': 192,\n",
       " 'movie': 192,\n",
       " 'find': 191,\n",
       " 'long': 190,\n",
       " 'watch': 188,\n",
       " 'tired': 188,\n",
       " 'done': 187,\n",
       " 'another': 185,\n",
       " 'man': 184,\n",
       " 'yet': 184,\n",
       " 'ever': 184,\n",
       " 'sure': 181,\n",
       " 'help': 180,\n",
       " 'cool': 180,\n",
       " 'phone': 179,\n",
       " 'ready': 172,\n",
       " 'went': 172,\n",
       " 'keep': 172,\n",
       " 'house': 168,\n",
       " 'already': 168,\n",
       " 'made': 168,\n",
       " 'start': 167,\n",
       " 'lost': 167,\n",
       " 'out': 166,\n",
       " 'someone': 165,\n",
       " 'game': 165,\n",
       " 'something': 163,\n",
       " 'summer': 161,\n",
       " 'damn': 161,\n",
       " 'follow': 159,\n",
       " 'should': 159,\n",
       " 'song': 159,\n",
       " 'old': 158,\n",
       " 'nothing': 157,\n",
       " 'wow': 157,\n",
       " 'weather': 155,\n",
       " 'hurt': 155,\n",
       " 'amazing': 154,\n",
       " 'did': 154,\n",
       " 'omg': 153,\n",
       " 'bit': 153,\n",
       " 'thought': 153,\n",
       " 'away': 152,\n",
       " 'more': 149,\n",
       " 'they': 148,\n",
       " 'early': 148,\n",
       " 'maybe': 148,\n",
       " 'here': 147,\n",
       " 'trying': 145,\n",
       " 'ugh': 143,\n",
       " 'mean': 143,\n",
       " 'sound': 143,\n",
       " 'what': 142,\n",
       " 'hot': 140,\n",
       " 'job': 140,\n",
       " 'guess': 140,\n",
       " 'pretty': 140,\n",
       " 'rain': 138,\n",
       " 'yay': 137,\n",
       " 'tell': 137,\n",
       " 'exam': 137,\n",
       " 'head': 136,\n",
       " 'try': 136,\n",
       " 'then': 136,\n",
       " 'glad': 135,\n",
       " 'live': 134,\n",
       " 'actually': 134,\n",
       " 'hear': 133,\n",
       " 'bored': 133,\n",
       " 'baby': 133,\n",
       " 'sun': 133,\n",
       " 'didn': 133,\n",
       " 'car': 133,\n",
       " 'play': 131,\n",
       " 'only': 129,\n",
       " 'birthday': 129,\n",
       " 'sunday': 129,\n",
       " 'about': 128,\n",
       " 'video': 128,\n",
       " 'god': 128,\n",
       " 'might': 127,\n",
       " 'missed': 127,\n",
       " 'call': 126,\n",
       " 'world': 126,\n",
       " 'left': 125,\n",
       " 'doe': 124,\n",
       " 'yesterday': 123,\n",
       " 'party': 123,\n",
       " 'big': 123,\n",
       " 'hard': 123,\n",
       " 'check': 122,\n",
       " 'later': 122,\n",
       " 'finally': 121,\n",
       " 'mom': 121,\n",
       " 'stuff': 120,\n",
       " 'com': 120,\n",
       " 'around': 119,\n",
       " 'follower': 118,\n",
       " 'monday': 118,\n",
       " 'she': 118,\n",
       " 'thats': 118,\n",
       " 'aww': 117,\n",
       " 'also': 117,\n",
       " 'excited': 117,\n",
       " 'use': 117,\n",
       " 'put': 117,\n",
       " 'luck': 116,\n",
       " 'saw': 116,\n",
       " 'her': 116,\n",
       " 'pic': 116,\n",
       " 'food': 115,\n",
       " 'end': 115,\n",
       " 'may': 114,\n",
       " 'found': 114,\n",
       " 'boy': 114,\n",
       " 'music': 114,\n",
       " 'said': 114,\n",
       " 'coming': 114,\n",
       " 'without': 113,\n",
       " 'two': 112,\n",
       " 'poor': 112,\n",
       " 'talk': 111,\n",
       " 'cold': 111,\n",
       " 'woke': 110,\n",
       " 'dinner': 109,\n",
       " 'friday': 109,\n",
       " 'everything': 108,\n",
       " 'very': 108,\n",
       " 'forward': 108,\n",
       " 'beautiful': 108,\n",
       " 'many': 108,\n",
       " 'tho': 108,\n",
       " 'give': 107,\n",
       " 'been': 107,\n",
       " 'stay': 106,\n",
       " 'must': 106,\n",
       " 'thinking': 104,\n",
       " 'idea': 104,\n",
       " 'listening': 104,\n",
       " 'making': 103,\n",
       " 'kid': 103,\n",
       " 'read': 103,\n",
       " 'when': 103,\n",
       " 'since': 102,\n",
       " 'finished': 101,\n",
       " 'gone': 100,\n",
       " 'far': 100,\n",
       " 'waiting': 99,\n",
       " 'late': 99,\n",
       " 'free': 99,\n",
       " 'how': 99,\n",
       " 'class': 98,\n",
       " 'picture': 98,\n",
       " 'book': 98,\n",
       " 'anymore': 98,\n",
       " 'stop': 97,\n",
       " 'family': 97,\n",
       " 'anyone': 96,\n",
       " 'place': 96,\n",
       " 'win': 96,\n",
       " 'funny': 96,\n",
       " 'coffee': 96,\n",
       " 'probably': 96,\n",
       " 'cry': 96,\n",
       " 'stupid': 95,\n",
       " 'shit': 95,\n",
       " 'saturday': 95,\n",
       " 'over': 95,\n",
       " 'enjoy': 94,\n",
       " 'totally': 94,\n",
       " 'almost': 93,\n",
       " 'least': 93,\n",
       " 'cause': 93,\n",
       " 'were': 92,\n",
       " 'his': 91,\n",
       " 'ill': 91,\n",
       " 'money': 90,\n",
       " 'missing': 90,\n",
       " 'month': 90,\n",
       " 'hair': 90,\n",
       " 'buy': 89,\n",
       " 'our': 89,\n",
       " 'playing': 89,\n",
       " 'iphone': 89,\n",
       " 'believe': 89,\n",
       " 'cute': 89,\n",
       " 'every': 88,\n",
       " 'lunch': 88,\n",
       " 'seen': 88,\n",
       " 'brother': 87,\n",
       " 'wrong': 87,\n",
       " 'dog': 86,\n",
       " 'anything': 86,\n",
       " 'hahaha': 86,\n",
       " 'didnt': 86,\n",
       " 'update': 85,\n",
       " 'mother': 85,\n",
       " 'enough': 84,\n",
       " 'till': 84,\n",
       " 'leave': 84,\n",
       " 'name': 84,\n",
       " 'fan': 84,\n",
       " 'hopefully': 84,\n",
       " 'outside': 83,\n",
       " 'news': 83,\n",
       " 'dream': 83,\n",
       " 'lovely': 83,\n",
       " 'eye': 82,\n",
       " 'super': 82,\n",
       " 'sweet': 82,\n",
       " 'beach': 82,\n",
       " 'wanted': 82,\n",
       " 'run': 81,\n",
       " 'mine': 80,\n",
       " 'welcome': 80,\n",
       " 'shopping': 80,\n",
       " 'off': 79,\n",
       " 'room': 79,\n",
       " 'dad': 78,\n",
       " 'busy': 77,\n",
       " 'doing': 76,\n",
       " 'half': 76,\n",
       " 'meet': 76,\n",
       " 'forgot': 76,\n",
       " 'change': 76,\n",
       " 'season': 75,\n",
       " 'eat': 75,\n",
       " 'okay': 75,\n",
       " 'goodnight': 75,\n",
       " 'them': 75,\n",
       " 'part': 75,\n",
       " 'real': 74,\n",
       " 'drink': 74,\n",
       " 'face': 74,\n",
       " 'problem': 73,\n",
       " 'won': 73,\n",
       " 'whole': 73,\n",
       " 'other': 72,\n",
       " 'else': 72,\n",
       " 'computer': 71,\n",
       " 'taking': 71,\n",
       " 'wake': 71,\n",
       " 'reading': 71,\n",
       " 'www': 71,\n",
       " 'following': 70,\n",
       " 'crazy': 70,\n",
       " 'reason': 70,\n",
       " 'rest': 70,\n",
       " 'trip': 70,\n",
       " 'soo': 70,\n",
       " 'minute': 70,\n",
       " 'ago': 70,\n",
       " 'hehe': 70,\n",
       " 'internet': 70,\n",
       " 'course': 69,\n",
       " 'word': 69,\n",
       " 'online': 69,\n",
       " 'took': 69,\n",
       " 'again': 69,\n",
       " 'cuz': 69,\n",
       " 'photo': 69,\n",
       " 'tried': 69,\n",
       " 'heard': 69,\n",
       " 'either': 68,\n",
       " 'fuck': 68,\n",
       " 'min': 68,\n",
       " 'breakfast': 68,\n",
       " 'hug': 68,\n",
       " 'pain': 68,\n",
       " 'bye': 68,\n",
       " 'eating': 68,\n",
       " 'being': 68,\n",
       " 'boo': 67,\n",
       " 'office': 67,\n",
       " 'reply': 67,\n",
       " 'headache': 67,\n",
       " 'true': 67,\n",
       " 'used': 66,\n",
       " 'quite': 66,\n",
       " 'final': 66,\n",
       " 'hand': 66,\n",
       " 'shower': 65,\n",
       " 'sitting': 65,\n",
       " 'walk': 65,\n",
       " 'hell': 65,\n",
       " 'train': 65,\n",
       " 'sigh': 65,\n",
       " 'link': 65,\n",
       " 'kinda': 64,\n",
       " 'email': 64,\n",
       " 'mind': 64,\n",
       " 'hello': 64,\n",
       " 'talking': 63,\n",
       " 'concert': 63,\n",
       " 'awww': 63,\n",
       " 'mileycyrus': 62,\n",
       " 'add': 62,\n",
       " 'lmao': 62,\n",
       " 'btw': 62,\n",
       " 'started': 62,\n",
       " 'heart': 61,\n",
       " 'break': 61,\n",
       " 'pay': 61,\n",
       " 'having': 61,\n",
       " 'enjoying': 61,\n",
       " 'from': 60,\n",
       " 'album': 60,\n",
       " 'plan': 60,\n",
       " 'full': 60,\n",
       " 'sooo': 60,\n",
       " 'care': 60,\n",
       " 'boring': 59,\n",
       " 'moment': 59,\n",
       " 'rock': 59,\n",
       " 'starting': 59,\n",
       " 'person': 59,\n",
       " 'definitely': 59,\n",
       " 'lady': 59,\n",
       " 'seems': 58,\n",
       " 'turn': 58,\n",
       " 'red': 58,\n",
       " 'haven': 58,\n",
       " 'cat': 58,\n",
       " 'raining': 58,\n",
       " 'mad': 58,\n",
       " 'text': 58,\n",
       " 'using': 57,\n",
       " 'those': 57,\n",
       " 'fine': 57,\n",
       " 'couple': 57,\n",
       " 'church': 57,\n",
       " 'remember': 57,\n",
       " 'leaving': 57,\n",
       " 'blog': 57,\n",
       " 'alone': 56,\n",
       " 'ticket': 56,\n",
       " 'same': 56,\n",
       " 'hit': 56,\n",
       " 'post': 56,\n",
       " 'nite': 56,\n",
       " 'holiday': 55,\n",
       " 'facebook': 55,\n",
       " 'down': 55,\n",
       " 'afternoon': 55,\n",
       " 'nap': 55,\n",
       " 'awake': 55,\n",
       " 'lucky': 54,\n",
       " 'came': 54,\n",
       " 'high': 54,\n",
       " 'him': 54,\n",
       " 'open': 54,\n",
       " 'kind': 54,\n",
       " 'ride': 54,\n",
       " 'sister': 54,\n",
       " 'their': 53,\n",
       " 'seriously': 53,\n",
       " 'stuck': 52,\n",
       " 'ask': 52,\n",
       " 'anyway': 52,\n",
       " 'til': 52,\n",
       " 'second': 52,\n",
       " 'watched': 52,\n",
       " 'bout': 52,\n",
       " 'happened': 52,\n",
       " 'called': 51,\n",
       " 'any': 51,\n",
       " 'sometimes': 51,\n",
       " 'smile': 51,\n",
       " 'yea': 51,\n",
       " 'foot': 51,\n",
       " 'drive': 51,\n",
       " 'worry': 51,\n",
       " 'bought': 50,\n",
       " 'driving': 50,\n",
       " 'wonderful': 50,\n",
       " 'move': 50,\n",
       " 'bring': 50,\n",
       " 'died': 50,\n",
       " 'agree': 50,\n",
       " 'favorite': 50,\n",
       " 'seem': 50,\n",
       " 'send': 50,\n",
       " 'asleep': 50,\n",
       " 'loved': 50,\n",
       " 'page': 50,\n",
       " 'broke': 49,\n",
       " 'running': 49,\n",
       " 'homework': 49,\n",
       " 'dude': 49,\n",
       " 'study': 49,\n",
       " 'tea': 49,\n",
       " 'three': 49,\n",
       " 'finish': 49,\n",
       " 'told': 49,\n",
       " 'heading': 49,\n",
       " 'crap': 49,\n",
       " 'tour': 48,\n",
       " 'top': 48,\n",
       " 'together': 48,\n",
       " 'line': 48,\n",
       " 'sleeping': 48,\n",
       " 'dance': 48,\n",
       " 'air': 48,\n",
       " 'listen': 48,\n",
       " 'slow': 48,\n",
       " 'sore': 48,\n",
       " 'happen': 48,\n",
       " 'ice': 48,\n",
       " 'visit': 48,\n",
       " 'instead': 48,\n",
       " 'hang': 47,\n",
       " 'laptop': 47,\n",
       " 'pool': 47,\n",
       " 'jealous': 47,\n",
       " 'water': 47,\n",
       " 'cut': 47,\n",
       " 'wedding': 47,\n",
       " 'story': 47,\n",
       " 'tommcfly': 47,\n",
       " 'apparently': 47,\n",
       " 'short': 47,\n",
       " 'fucking': 46,\n",
       " 'mum': 46,\n",
       " 'hmm': 46,\n",
       " 'doesn': 46,\n",
       " 'studying': 46,\n",
       " 'site': 46,\n",
       " 'test': 46,\n",
       " 'finger': 46,\n",
       " 'close': 46,\n",
       " 'woman': 46,\n",
       " 'able': 45,\n",
       " 'mac': 45,\n",
       " 'flight': 45,\n",
       " 'window': 45,\n",
       " 'goin': 45,\n",
       " 'lazy': 45,\n",
       " 'point': 45,\n",
       " 'question': 45,\n",
       " 'hoping': 45,\n",
       " 'set': 45,\n",
       " 'dead': 45,\n",
       " 'xxx': 45,\n",
       " 'ate': 45,\n",
       " 'chocolate': 44,\n",
       " 'sunshine': 44,\n",
       " 'evening': 44,\n",
       " 'london': 44,\n",
       " 'team': 44,\n",
       " 'seeing': 44,\n",
       " 'why': 44,\n",
       " 'sunny': 44,\n",
       " 'huge': 44,\n",
       " 'star': 43,\n",
       " 'city': 43,\n",
       " 'english': 43,\n",
       " 'perfect': 43,\n",
       " 'black': 43,\n",
       " 'lil': 43,\n",
       " 'voice': 43,\n",
       " 'answer': 43,\n",
       " 'loving': 43,\n",
       " 'soooo': 42,\n",
       " 'broken': 42,\n",
       " 'wont': 42,\n",
       " 'store': 42,\n",
       " 'past': 42,\n",
       " 'ive': 42,\n",
       " 'special': 42,\n",
       " 'park': 42,\n",
       " 'ahh': 42,\n",
       " 'such': 42,\n",
       " 'jonas': 42,\n",
       " 'town': 42,\n",
       " 'load': 42,\n",
       " 'doesnt': 42,\n",
       " 'write': 42,\n",
       " 'cream': 42,\n",
       " 'episode': 42,\n",
       " 'few': 41,\n",
       " 'unfortunately': 41,\n",
       " 'saying': 41,\n",
       " 'june': 41,\n",
       " 'forever': 41,\n",
       " 'fall': 41,\n",
       " 'list': 41,\n",
       " 'worst': 41,\n",
       " 'goodbye': 41,\n",
       " 'youtube': 41,\n",
       " 'drinking': 41,\n",
       " 'message': 40,\n",
       " 'light': 40,\n",
       " 'side': 40,\n",
       " 'wasn': 40,\n",
       " 'gym': 40,\n",
       " 'number': 40,\n",
       " 'ddlovato': 40,\n",
       " 'award': 40,\n",
       " 'shop': 40,\n",
       " 'vacation': 40,\n",
       " 'beer': 40,\n",
       " 'sims': 40,\n",
       " 'leg': 40,\n",
       " 'july': 39,\n",
       " 'followfriday': 39,\n",
       " 'hungry': 39,\n",
       " 'airport': 39,\n",
       " 'worth': 39,\n",
       " 'website': 39,\n",
       " 'google': 39,\n",
       " 'math': 39,\n",
       " 'spend': 39,\n",
       " 'fair': 39,\n",
       " 'figure': 38,\n",
       " 'rather': 38,\n",
       " 'understand': 38,\n",
       " 'plus': 38,\n",
       " 'paper': 38,\n",
       " 'pick': 38,\n",
       " 'worse': 38,\n",
       " 'sleepy': 38,\n",
       " 'fail': 38,\n",
       " 'chance': 38,\n",
       " 'weird': 38,\n",
       " 'stomach': 38,\n",
       " 'scared': 37,\n",
       " 'dear': 37,\n",
       " 'tweeting': 37,\n",
       " 'earlier': 37,\n",
       " 'green': 37,\n",
       " 'shame': 37,\n",
       " 'order': 37,\n",
       " 'yep': 37,\n",
       " 'than': 37,\n",
       " 'xoxo': 36,\n",
       " 'sat': 36,\n",
       " 'save': 36,\n",
       " 'account': 36,\n",
       " 'body': 36,\n",
       " 'join': 36,\n",
       " 'chat': 36,\n",
       " 'cousin': 36,\n",
       " 'hill': 36,\n",
       " 'band': 36,\n",
       " 'thx': 36,\n",
       " 'bet': 36,\n",
       " 'whats': 36,\n",
       " 'bus': 36,\n",
       " 'ppl': 36,\n",
       " 'shall': 36,\n",
       " 'parent': 36,\n",
       " 'catch': 35,\n",
       " 'longer': 35,\n",
       " 'fast': 35,\n",
       " 'power': 35,\n",
       " 'case': 35,\n",
       " 'horrible': 35,\n",
       " 'congrats': 35,\n",
       " 'safe': 35,\n",
       " 'wear': 35,\n",
       " 'self': 35,\n",
       " 'father': 35,\n",
       " 'wishing': 35,\n",
       " 'shoe': 34,\n",
       " 'due': 34,\n",
       " 'learn': 34,\n",
       " 'fly': 34,\n",
       " 'except': 34,\n",
       " 'blue': 34,\n",
       " 'ahhh': 34,\n",
       " 'cheer': 34,\n",
       " 'supposed': 34,\n",
       " 'bbq': 34,\n",
       " 'bag': 34,\n",
       " 'ipod': 34,\n",
       " 'cake': 34,\n",
       " 'nope': 33,\n",
       " 'download': 33,\n",
       " 'most': 33,\n",
       " 'project': 33,\n",
       " 'sale': 33,\n",
       " 'lakers': 33,\n",
       " 'note': 33,\n",
       " 'proud': 33,\n",
       " 'roll': 33,\n",
       " 'sign': 33,\n",
       " 'cleaning': 33,\n",
       " 'myself': 33,\n",
       " 'annoying': 33,\n",
       " 'forget': 33,\n",
       " 'writing': 33,\n",
       " 'state': 33,\n",
       " 'meeting': 32,\n",
       " 'wonder': 32,\n",
       " 'daughter': 32,\n",
       " 'waking': 32,\n",
       " 'isnt': 32,\n",
       " 'nobody': 32,\n",
       " 'cup': 32,\n",
       " 'twilight': 32,\n",
       " 'card': 32,\n",
       " 'son': 32,\n",
       " 'child': 32,\n",
       " 'slept': 32,\n",
       " 'dress': 32,\n",
       " 'mood': 32,\n",
       " 'small': 32,\n",
       " 'throat': 32,\n",
       " 'radio': 32,\n",
       " 'liked': 32,\n",
       " 'worked': 32,\n",
       " 'wtf': 32,\n",
       " 'taken': 32,\n",
       " 'support': 32,\n",
       " 'needed': 32,\n",
       " 'sadly': 31,\n",
       " 'bday': 31,\n",
       " 'sent': 31,\n",
       " 'spent': 31,\n",
       " 'beat': 31,\n",
       " 'jon': 31,\n",
       " 'plane': 31,\n",
       " 'gettin': 31,\n",
       " 'rainy': 31,\n",
       " 'luv': 31,\n",
       " 'kiss': 31,\n",
       " 'meant': 31,\n",
       " 'after': 31,\n",
       " 'guitar': 31,\n",
       " 'fell': 31,\n",
       " 'hanging': 31,\n",
       " 'mommy': 31,\n",
       " 'miley': 31,\n",
       " 'ball': 31,\n",
       " 'dvd': 31,\n",
       " 'idk': 30,\n",
       " 'singing': 30,\n",
       " 'moving': 30,\n",
       " 'pizza': 30,\n",
       " 'warm': 30,\n",
       " 'wednesday': 30,\n",
       " 'kill': 30,\n",
       " 'shot': 30,\n",
       " 'date': 30,\n",
       " 'tuesday': 30,\n",
       " 'hospital': 30,\n",
       " 'door': 30,\n",
       " 'vote': 30,\n",
       " 'woo': 30,\n",
       " 'thru': 30,\n",
       " 'die': 30,\n",
       " 'myspace': 30,\n",
       " 'buddy': 29,\n",
       " 'tom': 29,\n",
       " 'where': 29,\n",
       " 'copy': 29,\n",
       " 'mall': 29,\n",
       " 'wife': 29,\n",
       " 'tweetdeck': 29,\n",
       " 'these': 29,\n",
       " 'babe': 29,\n",
       " 'college': 29,\n",
       " 'garden': 29,\n",
       " 'havent': 29,\n",
       " 'flu': 29,\n",
       " 'huh': 29,\n",
       " 'mtv': 29,\n",
       " 'terrible': 29,\n",
       " 'realized': 29,\n",
       " 'shift': 29,\n",
       " 'vega': 29,\n",
       " 'fixed': 29,\n",
       " 'comment': 29,\n",
       " 'whatever': 29,\n",
       " 'clean': 29,\n",
       " 'lose': 28,\n",
       " 'wondering': 28,\n",
       " 'snow': 28,\n",
       " 'share': 28,\n",
       " 'future': 28,\n",
       " 'both': 28,\n",
       " 'pas': 28,\n",
       " 'especially': 28,\n",
       " 'different': 28,\n",
       " 'living': 28,\n",
       " 'doctor': 28,\n",
       " 'couldn': 28,\n",
       " 'coz': 28,\n",
       " 'bitch': 28,\n",
       " 'clothes': 28,\n",
       " 'along': 28,\n",
       " 'nick': 28,\n",
       " 'sex': 27,\n",
       " 'workout': 27,\n",
       " 'service': 27,\n",
       " 'wasnt': 27,\n",
       " 'fat': 27,\n",
       " 'fml': 27,\n",
       " 'camera': 27,\n",
       " 'gosh': 27,\n",
       " 'turned': 27,\n",
       " 'kate': 27,\n",
       " 'france': 27,\n",
       " 'fix': 27,\n",
       " 'upset': 27,\n",
       " 'version': 27,\n",
       " 'hmmm': 27,\n",
       " 'white': 27,\n",
       " 'walking': 27,\n",
       " 'david': 27,\n",
       " 'interview': 27,\n",
       " 'matter': 27,\n",
       " 'shirt': 27,\n",
       " 'wine': 27,\n",
       " 'giving': 27,\n",
       " 'before': 27,\n",
       " 'age': 27,\n",
       " 'looked': 27,\n",
       " 'officially': 27,\n",
       " 'record': 27,\n",
       " 'somewhere': 27,\n",
       " 'completely': 27,\n",
       " 'knew': 26,\n",
       " 'happens': 26,\n",
       " 'decided': 26,\n",
       " 'boyfriend': 26,\n",
       " 'bunch': 26,\n",
       " 'art': 26,\n",
       " 'everybody': 26,\n",
       " 'jonasbrothers': 26,\n",
       " 'behind': 26,\n",
       " 'inside': 26,\n",
       " 'arm': 26,\n",
       " 'alot': 26,\n",
       " 'packing': 26,\n",
       " 'while': 26,\n",
       " 'thursday': 26,\n",
       " 'joke': 26,\n",
       " 'hubby': 26,\n",
       " 'bike': 26,\n",
       " 'absolutely': 26,\n",
       " 'screen': 26,\n",
       " 'lesson': 26,\n",
       " 'peep': 26,\n",
       " 'interesting': 26,\n",
       " 'because': 26,\n",
       " 'hold': 26,\n",
       " 'relaxing': 26,\n",
       " 'client': 26,\n",
       " 'club': 26,\n",
       " 'revision': 26,\n",
       " 'nearly': 25,\n",
       " 'john': 25,\n",
       " 'bill': 25,\n",
       " 'low': 25,\n",
       " 'gorgeous': 25,\n",
       " 'price': 25,\n",
       " 'sit': 25,\n",
       " 'fit': 25,\n",
       " 'sort': 25,\n",
       " 'info': 25,\n",
       " 'moon': 25,\n",
       " 'ahead': 25,\n",
       " 'dark': 25,\n",
       " 'dumb': 25,\n",
       " 'return': 25,\n",
       " 'enjoyed': 25,\n",
       " 'pack': 25,\n",
       " 'mail': 25,\n",
       " 'delicious': 25,\n",
       " 'exhausted': 25,\n",
       " 'san': 25,\n",
       " 'staying': 25,\n",
       " 'easy': 25,\n",
       " 'brazil': 25,\n",
       " 'holy': 25,\n",
       " 'touch': 25,\n",
       " 'sum': 25,\n",
       " 'bar': 25,\n",
       " 'who': 24,\n",
       " 'web': 24,\n",
       " 'lame': 24,\n",
       " 'scary': 24,\n",
       " 'aint': 24,\n",
       " 'pop': 24,\n",
       " 'mention': 24,\n",
       " 'sing': 24,\n",
       " 'awful': 24,\n",
       " 'wit': 24,\n",
       " 'closed': 24,\n",
       " 'experience': 24,\n",
       " 'via': 24,\n",
       " 'met': 24,\n",
       " 'ohh': 24,\n",
       " 'assignment': 24,\n",
       " 'personal': 24,\n",
       " 'felt': 24,\n",
       " 'dying': 24,\n",
       " 'taylor': 24,\n",
       " 'joe': 24,\n",
       " 'doubt': 24,\n",
       " 'gave': 24,\n",
       " 'french': 24,\n",
       " 'stick': 23,\n",
       " 'currently': 23,\n",
       " 'burnt': 23,\n",
       " 'outta': 23,\n",
       " 'changed': 23,\n",
       " 'doin': 23,\n",
       " 'yummy': 23,\n",
       " 'isn': 23,\n",
       " 'deal': 23,\n",
       " 'quick': 23,\n",
       " 'tan': 23,\n",
       " 'hows': 23,\n",
       " 'lonely': 23,\n",
       " 'present': 23,\n",
       " 'track': 23,\n",
       " 'watchin': 23,\n",
       " 'dentist': 23,\n",
       " 'own': 23,\n",
       " 'others': 23,\n",
       " 'husband': 23,\n",
       " 'suppose': 23,\n",
       " 'company': 23,\n",
       " 'shut': 23,\n",
       " 'box': 23,\n",
       " 'cook': 23,\n",
       " 'button': 23,\n",
       " 'practice': 23,\n",
       " 'race': 23,\n",
       " 'vip': 23,\n",
       " 'kick': 23,\n",
       " 'dunno': 23,\n",
       " 'tummy': 23,\n",
       " 'sir': 23,\n",
       " 'laugh': 23,\n",
       " 'helping': 23,\n",
       " 'ear': 23,\n",
       " 'posted': 23,\n",
       " 'five': 23,\n",
       " 'yum': 23,\n",
       " 'type': 22,\n",
       " 'business': 22,\n",
       " 'channel': 22,\n",
       " 'chill': 22,\n",
       " 'ooh': 22,\n",
       " 'view': 22,\n",
       " 'connection': 22,\n",
       " 'jus': 22,\n",
       " 'magic': 22,\n",
       " 'often': 22,\n",
       " 'buying': 22,\n",
       " 'yup': 22,\n",
       " 'hangover': 22,\n",
       " 'pissed': 22,\n",
       " 'graduation': 22,\n",
       " 'thanx': 22,\n",
       " 'cavs': 22,\n",
       " 'puppy': 22,\n",
       " 'american': 22,\n",
       " 'app': 22,\n",
       " 'surprise': 22,\n",
       " 'sending': 22,\n",
       " 'alright': 22,\n",
       " 'taste': 22,\n",
       " 'killing': 22,\n",
       " 'paid': 22,\n",
       " 'round': 22,\n",
       " 'noticed': 22,\n",
       " 'storm': 22,\n",
       " 'war': 22,\n",
       " 'serious': 22,\n",
       " 'search': 22,\n",
       " 'article': 22,\n",
       " 'blackberry': 22,\n",
       " 'gay': 22,\n",
       " 'yall': 22,\n",
       " 'sky': 21,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dist = {k: v for k, v in sorted(new_dist.items(), key=lambda item: item[1], reverse=True)}\n",
    "new_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(new_dist.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day',\n",
       " 'get',\n",
       " 'good',\n",
       " 'you',\n",
       " 'like',\n",
       " 'quot',\n",
       " 'have',\n",
       " 'got',\n",
       " 'work',\n",
       " 'love',\n",
       " 'time',\n",
       " 'today',\n",
       " 'going',\n",
       " 'one',\n",
       " 'lol',\n",
       " 'back',\n",
       " 'know',\n",
       " 'want',\n",
       " 'really',\n",
       " 'amp',\n",
       " 'well',\n",
       " 'night',\n",
       " 'can',\n",
       " 'need',\n",
       " 'think',\n",
       " 'see',\n",
       " 'still',\n",
       " 'new',\n",
       " 'morning',\n",
       " 'thanks',\n",
       " 'home',\n",
       " 'that',\n",
       " 'feel',\n",
       " 'miss',\n",
       " 'just',\n",
       " 'twitter',\n",
       " 'much',\n",
       " 'hope',\n",
       " 'great',\n",
       " 'not',\n",
       " 'make',\n",
       " 'tomorrow',\n",
       " 'last',\n",
       " 'wish',\n",
       " 'are',\n",
       " 'all',\n",
       " 'and',\n",
       " 'haha',\n",
       " 'sad',\n",
       " 'bad',\n",
       " 'fun',\n",
       " 'sorry',\n",
       " 'would',\n",
       " 'week',\n",
       " 'come',\n",
       " 'happy',\n",
       " 'sleep',\n",
       " 'thing',\n",
       " 'tonight',\n",
       " 'this',\n",
       " 'way',\n",
       " 'friend',\n",
       " 'though',\n",
       " 'right',\n",
       " 'will',\n",
       " 'don',\n",
       " 'for',\n",
       " 'hate',\n",
       " 'gon',\n",
       " 'had',\n",
       " 'nice',\n",
       " 'getting',\n",
       " 'better',\n",
       " 'watching',\n",
       " 'look',\n",
       " 'say',\n",
       " 'yeah',\n",
       " 'your',\n",
       " 'hour',\n",
       " 'weekend',\n",
       " 'wait',\n",
       " 'could',\n",
       " 'take',\n",
       " 'bed',\n",
       " 'yes',\n",
       " 'too',\n",
       " 'guy',\n",
       " 'next',\n",
       " 'people',\n",
       " 'school',\n",
       " 'even',\n",
       " 'best',\n",
       " 'feeling',\n",
       " 'awesome',\n",
       " 'thank',\n",
       " 'now',\n",
       " 'hey',\n",
       " 'never',\n",
       " 'dont',\n",
       " 'working',\n",
       " 'year',\n",
       " 'wan',\n",
       " 'with',\n",
       " 'cant',\n",
       " 'tweet',\n",
       " 'but',\n",
       " 'let',\n",
       " 'there',\n",
       " 'looking',\n",
       " 'little',\n",
       " 'life',\n",
       " 'some',\n",
       " 'show',\n",
       " 'first',\n",
       " 'girl',\n",
       " 'sick',\n",
       " 'everyone',\n",
       " 'lot',\n",
       " 'suck',\n",
       " 'always',\n",
       " 'soon',\n",
       " 'please',\n",
       " 'movie',\n",
       " 'find',\n",
       " 'long',\n",
       " 'watch',\n",
       " 'tired',\n",
       " 'done',\n",
       " 'another',\n",
       " 'man',\n",
       " 'yet',\n",
       " 'ever',\n",
       " 'sure',\n",
       " 'help',\n",
       " 'cool',\n",
       " 'phone',\n",
       " 'ready',\n",
       " 'went',\n",
       " 'keep',\n",
       " 'house',\n",
       " 'already',\n",
       " 'made',\n",
       " 'start',\n",
       " 'lost',\n",
       " 'out',\n",
       " 'someone',\n",
       " 'game',\n",
       " 'something',\n",
       " 'summer',\n",
       " 'damn',\n",
       " 'follow',\n",
       " 'should',\n",
       " 'song',\n",
       " 'old',\n",
       " 'nothing',\n",
       " 'wow',\n",
       " 'weather',\n",
       " 'hurt',\n",
       " 'amazing',\n",
       " 'did',\n",
       " 'omg',\n",
       " 'bit',\n",
       " 'thought',\n",
       " 'away',\n",
       " 'more',\n",
       " 'they',\n",
       " 'early',\n",
       " 'maybe',\n",
       " 'here',\n",
       " 'trying',\n",
       " 'ugh',\n",
       " 'mean',\n",
       " 'sound',\n",
       " 'what',\n",
       " 'hot',\n",
       " 'job',\n",
       " 'guess',\n",
       " 'pretty',\n",
       " 'rain',\n",
       " 'yay',\n",
       " 'tell',\n",
       " 'exam',\n",
       " 'head',\n",
       " 'try',\n",
       " 'then',\n",
       " 'glad',\n",
       " 'live',\n",
       " 'actually',\n",
       " 'hear',\n",
       " 'bored',\n",
       " 'baby',\n",
       " 'sun',\n",
       " 'didn',\n",
       " 'car',\n",
       " 'play',\n",
       " 'only',\n",
       " 'birthday',\n",
       " 'sunday',\n",
       " 'about',\n",
       " 'video',\n",
       " 'god',\n",
       " 'might',\n",
       " 'missed',\n",
       " 'call',\n",
       " 'world',\n",
       " 'left',\n",
       " 'doe',\n",
       " 'yesterday',\n",
       " 'party',\n",
       " 'big',\n",
       " 'hard',\n",
       " 'check',\n",
       " 'later',\n",
       " 'finally',\n",
       " 'mom',\n",
       " 'stuff',\n",
       " 'com',\n",
       " 'around',\n",
       " 'follower',\n",
       " 'monday',\n",
       " 'she',\n",
       " 'thats',\n",
       " 'aww',\n",
       " 'also',\n",
       " 'excited',\n",
       " 'use',\n",
       " 'put',\n",
       " 'luck',\n",
       " 'saw',\n",
       " 'her',\n",
       " 'pic',\n",
       " 'food',\n",
       " 'end',\n",
       " 'may',\n",
       " 'found',\n",
       " 'boy',\n",
       " 'music',\n",
       " 'said',\n",
       " 'coming',\n",
       " 'without',\n",
       " 'two',\n",
       " 'poor',\n",
       " 'talk',\n",
       " 'cold',\n",
       " 'woke',\n",
       " 'dinner',\n",
       " 'friday',\n",
       " 'everything',\n",
       " 'very',\n",
       " 'forward',\n",
       " 'beautiful',\n",
       " 'many',\n",
       " 'tho',\n",
       " 'give',\n",
       " 'been',\n",
       " 'stay',\n",
       " 'must',\n",
       " 'thinking',\n",
       " 'idea',\n",
       " 'listening',\n",
       " 'making',\n",
       " 'kid',\n",
       " 'read',\n",
       " 'when',\n",
       " 'since',\n",
       " 'finished',\n",
       " 'gone',\n",
       " 'far',\n",
       " 'waiting',\n",
       " 'late',\n",
       " 'free',\n",
       " 'how',\n",
       " 'class',\n",
       " 'picture',\n",
       " 'book',\n",
       " 'anymore',\n",
       " 'stop',\n",
       " 'family',\n",
       " 'anyone',\n",
       " 'place',\n",
       " 'win',\n",
       " 'funny',\n",
       " 'coffee',\n",
       " 'probably',\n",
       " 'cry',\n",
       " 'stupid',\n",
       " 'shit',\n",
       " 'saturday',\n",
       " 'over',\n",
       " 'enjoy',\n",
       " 'totally',\n",
       " 'almost',\n",
       " 'least',\n",
       " 'cause',\n",
       " 'were',\n",
       " 'his',\n",
       " 'ill',\n",
       " 'money',\n",
       " 'missing',\n",
       " 'month',\n",
       " 'hair',\n",
       " 'buy',\n",
       " 'our',\n",
       " 'playing',\n",
       " 'iphone',\n",
       " 'believe',\n",
       " 'cute',\n",
       " 'every',\n",
       " 'lunch',\n",
       " 'seen',\n",
       " 'brother',\n",
       " 'wrong',\n",
       " 'dog',\n",
       " 'anything',\n",
       " 'hahaha',\n",
       " 'didnt',\n",
       " 'update',\n",
       " 'mother',\n",
       " 'enough',\n",
       " 'till',\n",
       " 'leave',\n",
       " 'name',\n",
       " 'fan',\n",
       " 'hopefully',\n",
       " 'outside',\n",
       " 'news',\n",
       " 'dream',\n",
       " 'lovely',\n",
       " 'eye',\n",
       " 'super',\n",
       " 'sweet',\n",
       " 'beach',\n",
       " 'wanted',\n",
       " 'run',\n",
       " 'mine',\n",
       " 'welcome',\n",
       " 'shopping',\n",
       " 'off',\n",
       " 'room',\n",
       " 'dad',\n",
       " 'busy',\n",
       " 'doing',\n",
       " 'half',\n",
       " 'meet',\n",
       " 'forgot',\n",
       " 'change',\n",
       " 'season',\n",
       " 'eat',\n",
       " 'okay',\n",
       " 'goodnight',\n",
       " 'them',\n",
       " 'part',\n",
       " 'real',\n",
       " 'drink',\n",
       " 'face',\n",
       " 'problem',\n",
       " 'won',\n",
       " 'whole',\n",
       " 'other',\n",
       " 'else',\n",
       " 'computer',\n",
       " 'taking',\n",
       " 'wake',\n",
       " 'reading',\n",
       " 'www',\n",
       " 'following',\n",
       " 'crazy',\n",
       " 'reason',\n",
       " 'rest',\n",
       " 'trip',\n",
       " 'soo',\n",
       " 'minute',\n",
       " 'ago',\n",
       " 'hehe',\n",
       " 'internet',\n",
       " 'course',\n",
       " 'word',\n",
       " 'online',\n",
       " 'took',\n",
       " 'again',\n",
       " 'cuz',\n",
       " 'photo',\n",
       " 'tried',\n",
       " 'heard',\n",
       " 'either',\n",
       " 'fuck',\n",
       " 'min',\n",
       " 'breakfast',\n",
       " 'hug',\n",
       " 'pain',\n",
       " 'bye',\n",
       " 'eating',\n",
       " 'being',\n",
       " 'boo',\n",
       " 'office',\n",
       " 'reply',\n",
       " 'headache',\n",
       " 'true',\n",
       " 'used',\n",
       " 'quite',\n",
       " 'final',\n",
       " 'hand',\n",
       " 'shower',\n",
       " 'sitting',\n",
       " 'walk',\n",
       " 'hell',\n",
       " 'train',\n",
       " 'sigh',\n",
       " 'link',\n",
       " 'kinda',\n",
       " 'email',\n",
       " 'mind',\n",
       " 'hello',\n",
       " 'talking',\n",
       " 'concert',\n",
       " 'awww',\n",
       " 'mileycyrus',\n",
       " 'add',\n",
       " 'lmao',\n",
       " 'btw',\n",
       " 'started',\n",
       " 'heart',\n",
       " 'break',\n",
       " 'pay',\n",
       " 'having',\n",
       " 'enjoying',\n",
       " 'from',\n",
       " 'album',\n",
       " 'plan',\n",
       " 'full',\n",
       " 'sooo',\n",
       " 'care',\n",
       " 'boring',\n",
       " 'moment',\n",
       " 'rock',\n",
       " 'starting',\n",
       " 'person',\n",
       " 'definitely',\n",
       " 'lady',\n",
       " 'seems',\n",
       " 'turn',\n",
       " 'red',\n",
       " 'haven',\n",
       " 'cat',\n",
       " 'raining',\n",
       " 'mad',\n",
       " 'text',\n",
       " 'using',\n",
       " 'those',\n",
       " 'fine',\n",
       " 'couple',\n",
       " 'church',\n",
       " 'remember',\n",
       " 'leaving',\n",
       " 'blog',\n",
       " 'alone',\n",
       " 'ticket',\n",
       " 'same',\n",
       " 'hit',\n",
       " 'post',\n",
       " 'nite',\n",
       " 'holiday',\n",
       " 'facebook',\n",
       " 'down',\n",
       " 'afternoon',\n",
       " 'nap',\n",
       " 'awake',\n",
       " 'lucky',\n",
       " 'came',\n",
       " 'high',\n",
       " 'him',\n",
       " 'open',\n",
       " 'kind',\n",
       " 'ride',\n",
       " 'sister',\n",
       " 'their',\n",
       " 'seriously',\n",
       " 'stuck',\n",
       " 'ask',\n",
       " 'anyway',\n",
       " 'til',\n",
       " 'second',\n",
       " 'watched',\n",
       " 'bout',\n",
       " 'happened',\n",
       " 'called',\n",
       " 'any',\n",
       " 'sometimes',\n",
       " 'smile',\n",
       " 'yea',\n",
       " 'foot',\n",
       " 'drive',\n",
       " 'worry',\n",
       " 'bought',\n",
       " 'driving',\n",
       " 'wonderful',\n",
       " 'move',\n",
       " 'bring',\n",
       " 'died',\n",
       " 'agree',\n",
       " 'favorite',\n",
       " 'seem',\n",
       " 'send',\n",
       " 'asleep',\n",
       " 'loved',\n",
       " 'page',\n",
       " 'broke',\n",
       " 'running',\n",
       " 'homework',\n",
       " 'dude',\n",
       " 'study',\n",
       " 'tea',\n",
       " 'three',\n",
       " 'finish',\n",
       " 'told',\n",
       " 'heading',\n",
       " 'crap',\n",
       " 'tour',\n",
       " 'top',\n",
       " 'together',\n",
       " 'line',\n",
       " 'sleeping',\n",
       " 'dance',\n",
       " 'air',\n",
       " 'listen',\n",
       " 'slow',\n",
       " 'sore',\n",
       " 'happen',\n",
       " 'ice',\n",
       " 'visit',\n",
       " 'instead',\n",
       " 'hang',\n",
       " 'laptop',\n",
       " 'pool',\n",
       " 'jealous',\n",
       " 'water',\n",
       " 'cut',\n",
       " 'wedding',\n",
       " 'story',\n",
       " 'tommcfly',\n",
       " 'apparently',\n",
       " 'short',\n",
       " 'fucking',\n",
       " 'mum',\n",
       " 'hmm',\n",
       " 'doesn',\n",
       " 'studying',\n",
       " 'site',\n",
       " 'test',\n",
       " 'finger',\n",
       " 'close',\n",
       " 'woman',\n",
       " 'able',\n",
       " 'mac',\n",
       " 'flight',\n",
       " 'window',\n",
       " 'goin',\n",
       " 'lazy',\n",
       " 'point',\n",
       " 'question',\n",
       " 'hoping',\n",
       " 'set',\n",
       " 'dead',\n",
       " 'xxx',\n",
       " 'ate',\n",
       " 'chocolate',\n",
       " 'sunshine',\n",
       " 'evening',\n",
       " 'london',\n",
       " 'team',\n",
       " 'seeing',\n",
       " 'why',\n",
       " 'sunny',\n",
       " 'huge',\n",
       " 'star',\n",
       " 'city',\n",
       " 'english',\n",
       " 'perfect',\n",
       " 'black',\n",
       " 'lil',\n",
       " 'voice',\n",
       " 'answer',\n",
       " 'loving',\n",
       " 'soooo',\n",
       " 'broken',\n",
       " 'wont',\n",
       " 'store',\n",
       " 'past',\n",
       " 'ive',\n",
       " 'special',\n",
       " 'park',\n",
       " 'ahh',\n",
       " 'such',\n",
       " 'jonas',\n",
       " 'town',\n",
       " 'load',\n",
       " 'doesnt',\n",
       " 'write',\n",
       " 'cream',\n",
       " 'episode',\n",
       " 'few',\n",
       " 'unfortunately',\n",
       " 'saying',\n",
       " 'june',\n",
       " 'forever',\n",
       " 'fall',\n",
       " 'list',\n",
       " 'worst',\n",
       " 'goodbye',\n",
       " 'youtube',\n",
       " 'drinking',\n",
       " 'message',\n",
       " 'light',\n",
       " 'side',\n",
       " 'wasn',\n",
       " 'gym',\n",
       " 'number',\n",
       " 'ddlovato',\n",
       " 'award',\n",
       " 'shop',\n",
       " 'vacation',\n",
       " 'beer',\n",
       " 'sims',\n",
       " 'leg',\n",
       " 'july',\n",
       " 'followfriday',\n",
       " 'hungry',\n",
       " 'airport',\n",
       " 'worth',\n",
       " 'website',\n",
       " 'google',\n",
       " 'math',\n",
       " 'spend',\n",
       " 'fair',\n",
       " 'figure',\n",
       " 'rather',\n",
       " 'understand',\n",
       " 'plus',\n",
       " 'paper',\n",
       " 'pick',\n",
       " 'worse',\n",
       " 'sleepy',\n",
       " 'fail',\n",
       " 'chance',\n",
       " 'weird',\n",
       " 'stomach',\n",
       " 'scared',\n",
       " 'dear',\n",
       " 'tweeting',\n",
       " 'earlier',\n",
       " 'green',\n",
       " 'shame',\n",
       " 'order',\n",
       " 'yep',\n",
       " 'than',\n",
       " 'xoxo',\n",
       " 'sat',\n",
       " 'save',\n",
       " 'account',\n",
       " 'body',\n",
       " 'join',\n",
       " 'chat',\n",
       " 'cousin',\n",
       " 'hill',\n",
       " 'band',\n",
       " 'thx',\n",
       " 'bet',\n",
       " 'whats',\n",
       " 'bus',\n",
       " 'ppl',\n",
       " 'shall',\n",
       " 'parent',\n",
       " 'catch',\n",
       " 'longer',\n",
       " 'fast',\n",
       " 'power',\n",
       " 'case',\n",
       " 'horrible',\n",
       " 'congrats',\n",
       " 'safe',\n",
       " 'wear',\n",
       " 'self',\n",
       " 'father',\n",
       " 'wishing',\n",
       " 'shoe',\n",
       " 'due',\n",
       " 'learn',\n",
       " 'fly',\n",
       " 'except',\n",
       " 'blue',\n",
       " 'ahhh',\n",
       " 'cheer',\n",
       " 'supposed',\n",
       " 'bbq',\n",
       " 'bag',\n",
       " 'ipod',\n",
       " 'cake',\n",
       " 'nope',\n",
       " 'download',\n",
       " 'most',\n",
       " 'project',\n",
       " 'sale',\n",
       " 'lakers',\n",
       " 'note',\n",
       " 'proud',\n",
       " 'roll',\n",
       " 'sign',\n",
       " 'cleaning',\n",
       " 'myself',\n",
       " 'annoying',\n",
       " 'forget',\n",
       " 'writing',\n",
       " 'state',\n",
       " 'meeting',\n",
       " 'wonder',\n",
       " 'daughter',\n",
       " 'waking',\n",
       " 'isnt',\n",
       " 'nobody',\n",
       " 'cup',\n",
       " 'twilight',\n",
       " 'card',\n",
       " 'son',\n",
       " 'child',\n",
       " 'slept',\n",
       " 'dress',\n",
       " 'mood',\n",
       " 'small',\n",
       " 'throat',\n",
       " 'radio',\n",
       " 'liked',\n",
       " 'worked',\n",
       " 'wtf',\n",
       " 'taken',\n",
       " 'support',\n",
       " 'needed',\n",
       " 'sadly',\n",
       " 'bday',\n",
       " 'sent',\n",
       " 'spent',\n",
       " 'beat',\n",
       " 'jon',\n",
       " 'plane',\n",
       " 'gettin',\n",
       " 'rainy',\n",
       " 'luv',\n",
       " 'kiss',\n",
       " 'meant',\n",
       " 'after',\n",
       " 'guitar',\n",
       " 'fell',\n",
       " 'hanging',\n",
       " 'mommy',\n",
       " 'miley',\n",
       " 'ball',\n",
       " 'dvd',\n",
       " 'idk',\n",
       " 'singing',\n",
       " 'moving',\n",
       " 'pizza',\n",
       " 'warm',\n",
       " 'wednesday',\n",
       " 'kill',\n",
       " 'shot',\n",
       " 'date',\n",
       " 'tuesday',\n",
       " 'hospital',\n",
       " 'door',\n",
       " 'vote',\n",
       " 'woo',\n",
       " 'thru',\n",
       " 'die',\n",
       " 'myspace',\n",
       " 'buddy',\n",
       " 'tom',\n",
       " 'where',\n",
       " 'copy',\n",
       " 'mall',\n",
       " 'wife',\n",
       " 'tweetdeck',\n",
       " 'these',\n",
       " 'babe',\n",
       " 'college',\n",
       " 'garden',\n",
       " 'havent',\n",
       " 'flu',\n",
       " 'huh',\n",
       " 'mtv',\n",
       " 'terrible',\n",
       " 'realized',\n",
       " 'shift',\n",
       " 'vega',\n",
       " 'fixed',\n",
       " 'comment',\n",
       " 'whatever',\n",
       " 'clean',\n",
       " 'lose',\n",
       " 'wondering',\n",
       " 'snow',\n",
       " 'share',\n",
       " 'future',\n",
       " 'both',\n",
       " 'pas',\n",
       " 'especially',\n",
       " 'different',\n",
       " 'living',\n",
       " 'doctor',\n",
       " 'couldn',\n",
       " 'coz',\n",
       " 'bitch',\n",
       " 'clothes',\n",
       " 'along',\n",
       " 'nick',\n",
       " 'sex',\n",
       " 'workout',\n",
       " 'service',\n",
       " 'wasnt',\n",
       " 'fat',\n",
       " 'fml',\n",
       " 'camera',\n",
       " 'gosh',\n",
       " 'turned',\n",
       " 'kate',\n",
       " 'france',\n",
       " 'fix',\n",
       " 'upset',\n",
       " 'version',\n",
       " 'hmmm',\n",
       " 'white',\n",
       " 'walking',\n",
       " 'david',\n",
       " 'interview',\n",
       " 'matter',\n",
       " 'shirt',\n",
       " 'wine',\n",
       " 'giving',\n",
       " 'before',\n",
       " 'age',\n",
       " 'looked',\n",
       " 'officially',\n",
       " 'record',\n",
       " 'somewhere',\n",
       " 'completely',\n",
       " 'knew',\n",
       " 'happens',\n",
       " 'decided',\n",
       " 'boyfriend',\n",
       " 'bunch',\n",
       " 'art',\n",
       " 'everybody',\n",
       " 'jonasbrothers',\n",
       " 'behind',\n",
       " 'inside',\n",
       " 'arm',\n",
       " 'alot',\n",
       " 'packing',\n",
       " 'while',\n",
       " 'thursday',\n",
       " 'joke',\n",
       " 'hubby',\n",
       " 'bike',\n",
       " 'absolutely',\n",
       " 'screen',\n",
       " 'lesson',\n",
       " 'peep',\n",
       " 'interesting',\n",
       " 'because',\n",
       " 'hold',\n",
       " 'relaxing',\n",
       " 'client',\n",
       " 'club',\n",
       " 'revision',\n",
       " 'nearly',\n",
       " 'john',\n",
       " 'bill',\n",
       " 'low',\n",
       " 'gorgeous',\n",
       " 'price',\n",
       " 'sit',\n",
       " 'fit',\n",
       " 'sort',\n",
       " 'info',\n",
       " 'moon',\n",
       " 'ahead',\n",
       " 'dark',\n",
       " 'dumb',\n",
       " 'return',\n",
       " 'enjoyed',\n",
       " 'pack',\n",
       " 'mail',\n",
       " 'delicious',\n",
       " 'exhausted',\n",
       " 'san',\n",
       " 'staying',\n",
       " 'easy',\n",
       " 'brazil',\n",
       " 'holy',\n",
       " 'touch',\n",
       " 'sum',\n",
       " 'bar',\n",
       " 'who',\n",
       " 'web',\n",
       " 'lame',\n",
       " 'scary',\n",
       " 'aint',\n",
       " 'pop',\n",
       " 'mention',\n",
       " 'sing',\n",
       " 'awful',\n",
       " 'wit',\n",
       " 'closed',\n",
       " 'experience',\n",
       " 'via',\n",
       " 'met',\n",
       " 'ohh',\n",
       " 'assignment',\n",
       " 'personal',\n",
       " 'felt',\n",
       " 'dying',\n",
       " 'taylor',\n",
       " 'joe',\n",
       " 'doubt',\n",
       " 'gave',\n",
       " 'french',\n",
       " 'stick',\n",
       " 'currently',\n",
       " 'burnt',\n",
       " 'outta',\n",
       " 'changed',\n",
       " 'doin',\n",
       " 'yummy',\n",
       " 'isn',\n",
       " 'deal',\n",
       " 'quick',\n",
       " 'tan',\n",
       " 'hows',\n",
       " 'lonely',\n",
       " 'present',\n",
       " 'track',\n",
       " 'watchin',\n",
       " 'dentist',\n",
       " 'own',\n",
       " 'others',\n",
       " 'husband',\n",
       " 'suppose',\n",
       " 'company',\n",
       " 'shut',\n",
       " 'box',\n",
       " 'cook',\n",
       " 'button',\n",
       " 'practice',\n",
       " 'race',\n",
       " 'vip',\n",
       " 'kick',\n",
       " 'dunno',\n",
       " 'tummy',\n",
       " 'sir',\n",
       " 'laugh',\n",
       " 'helping',\n",
       " 'ear',\n",
       " 'posted',\n",
       " 'five',\n",
       " 'yum',\n",
       " 'type',\n",
       " 'business',\n",
       " 'channel',\n",
       " 'chill',\n",
       " 'ooh',\n",
       " 'view',\n",
       " 'connection',\n",
       " 'jus',\n",
       " 'magic',\n",
       " 'often',\n",
       " 'buying',\n",
       " 'yup',\n",
       " 'hangover',\n",
       " 'pissed',\n",
       " 'graduation',\n",
       " 'thanx',\n",
       " 'cavs',\n",
       " 'puppy',\n",
       " 'american',\n",
       " 'app',\n",
       " 'surprise',\n",
       " 'sending',\n",
       " 'alright',\n",
       " 'taste',\n",
       " 'killing',\n",
       " 'paid',\n",
       " 'round',\n",
       " 'noticed',\n",
       " 'storm',\n",
       " 'war',\n",
       " 'serious',\n",
       " 'search',\n",
       " 'article',\n",
       " 'blackberry',\n",
       " 'gay',\n",
       " 'yall',\n",
       " 'sky',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Features\n",
    "\n",
    "Now let's build the features. Using the top 5,000 words, create a 2-dimensional matrix to record whether each of those words is contained in each document (tweet). Then you also have an output column to indicate whether the sentiment in each tweet is positive. For example, assuming your bag of words has 5 items (`['one', 'two', 'three', 'four', 'five']`) out of 4 documents (`['A', 'B', 'C', 'D']`), your feature set is essentially:\n",
    "\n",
    "| Doc | one | two | three | four | five | is_positive |\n",
    "|---|---|---|---|---|---|---|\n",
    "| A | True | False | False | True | False | True |\n",
    "| B | False | False | False | True | True | False |\n",
    "| C | False | True | False | False | False | True |\n",
    "| D | True | False | False | False | True | False|\n",
    "\n",
    "However, because the `nltk.NaiveBayesClassifier.train` class we will use in the next step does not work with Pandas dataframe, the structure of your feature set should be converted to the Python list looking like below:\n",
    "\n",
    "```python\n",
    "[\n",
    "\t({\n",
    "\t\t'one': True,\n",
    "\t\t'two': False,\n",
    "\t\t'three': False,\n",
    "\t\t'four': True,\n",
    "\t\t'five': False\n",
    "\t}, True),\n",
    "\t({\n",
    "\t\t'one': False,\n",
    "\t\t'two': False,\n",
    "\t\t'three': False,\n",
    "\t\t'four': True,\n",
    "\t\t'five': True\n",
    "\t}, False),\n",
    "\t({\n",
    "\t\t'one': False,\n",
    "\t\t'two': True,\n",
    "\t\t'three': False,\n",
    "\t\t'four': False,\n",
    "\t\t'five': False\n",
    "\t}, True),\n",
    "\t({\n",
    "\t\t'one': True,\n",
    "\t\t'two': False,\n",
    "\t\t'three': False,\n",
    "\t\t'four': False,\n",
    "\t\t'five': True\n",
    "\t}, False)\n",
    "]\n",
    "```\n",
    "\n",
    "To help you in this step, watch the [following video](https://www.youtube.com/watch?v=-vVskDsHcVc) to learn how to build the feature set with Python and NLTK. The source code in this video can be found [here](https://pythonprogramming.net/words-as-features-nltk-tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Building Features](building-features.jpg)](https://www.youtube.com/watch?v=-vVskDsHcVc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in corpus:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(0,len(data[\"text_processed\"])):\n",
    "    x = find_features(list(data[\"text_processed\"])[i])\n",
    "    features.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_positive = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for i in range(0,len(data[\"text\"])):\n",
    "    x = analyzer.polarity_scores(list(data[\"text\"])[i])\n",
    "    if x[\"compound\"] > 0:\n",
    "        is_positive.append(True)\n",
    "    elif x[\"compound\"] == 0:\n",
    "        is_positive.append(False)\n",
    "    else:\n",
    "        is_positive.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, False, True, False, False, True, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9342\n",
      "10658\n"
     ]
    }
   ],
   "source": [
    "print(is_positive.count(True))\n",
    "print(is_positive.count(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There is no need to correct class imbalance, since the number of positive reviews \n",
    "### is more or less equal to the number of negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = list(zip(features, is_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Traininng Naive Bayes Model\n",
    "\n",
    "In this step you will split your feature set into a training and a test set. Then you will create a Bayes classifier instance using `nltk.NaiveBayesClassifier.train` ([example](https://www.nltk.org/book/ch06.html)) to train with the training dataset.\n",
    "\n",
    "After training the model, call `classifier.show_most_informative_features()` to inspect the most important features. The output will look like:\n",
    "\n",
    "```\n",
    "Most Informative Features\n",
    "\t    snow = True            False : True   =     34.3 : 1.0\n",
    "\t  easter = True            False : True   =     26.2 : 1.0\n",
    "\t headach = True            False : True   =     20.9 : 1.0\n",
    "\t    argh = True            False : True   =     17.6 : 1.0\n",
    "\tunfortun = True            False : True   =     16.9 : 1.0\n",
    "\t    jona = True             True : False  =     16.2 : 1.0\n",
    "\t     ach = True            False : True   =     14.9 : 1.0\n",
    "\t     sad = True            False : True   =     13.0 : 1.0\n",
    "\t  parent = True            False : True   =     12.9 : 1.0\n",
    "\t  spring = True            False : True   =     12.7 : 1.0\n",
    "```\n",
    "\n",
    "The [following video](https://www.youtube.com/watch?v=rISOsUaTrO4) will help you complete this step. The source code in this video can be found [here](https://pythonprogramming.net/naive-bayes-classifier-nltk-tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Building and Training NB](nb-model-building.jpg)](https://www.youtube.com/watch?v=rISOsUaTrO4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data_model[:16000]\n",
    "testing_set = data_model[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               beautiful = True             True : False  =     39.0 : 1.0\n",
      "                  thanks = True             True : False  =     29.5 : 1.0\n",
      "                  loving = True             True : False  =     27.8 : 1.0\n",
      "                 awesome = True             True : False  =     23.8 : 1.0\n",
      "                    xoxo = True             True : False  =     23.2 : 1.0\n",
      "                enjoying = True             True : False  =     22.6 : 1.0\n",
      "                   thank = True             True : False  =     21.9 : 1.0\n",
      "                     thx = True             True : False  =     21.7 : 1.0\n",
      "                congrats = True             True : False  =     20.9 : 1.0\n",
      "                 welcome = True             True : False  =     20.4 : 1.0\n",
      "                    love = True             True : False  =     17.6 : 1.0\n",
      "                   smile = True             True : False  =     17.6 : 1.0\n",
      "                   worst = True            False : True   =     17.2 : 1.0\n",
      "                  hahaha = True             True : False  =     16.6 : 1.0\n",
      "                     yay = True             True : False  =     16.2 : 1.0\n",
      "                   great = True             True : False  =     15.9 : 1.0\n",
      "                   sweet = True             True : False  =     15.6 : 1.0\n",
      "                    free = True             True : False  =     15.0 : 1.0\n",
      "                     woo = True             True : False  =     14.8 : 1.0\n",
      "                   happy = True             True : False  =     14.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Naive Bayes Model\n",
    "\n",
    "Now we'll test our classifier with the test dataset. This is done by calling `nltk.classify.accuracy(classifier, test)`.\n",
    "\n",
    "As mentioned in one of the tutorial videos, a Naive Bayes model is considered OK if your accuracy score is over 0.6. If your accuracy score is over 0.7, you've done a great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy score: 0.8245\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy score:\",(nltk.classify.accuracy(classifier, testing_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Yey! Accuracy of 0.8245 :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 1: Improve Model Performance\n",
    "\n",
    "If you are still not exhausted so far and want to dig deeper, try to improve your classifier performance. There are many aspects you can dig into, for example:\n",
    "\n",
    "* Improve stemming and lemmatization. Inspect your bag of words and the most important features. Are there any words you should furuther remove from analysis? You can append these words to further remove to the stop words list.\n",
    "\n",
    "* Remember we only used the top 5,000 features to build model? Try using different numbers of top features. The bottom line is to use as few features as you can without compromising your model performance. The fewer features you select into your model, the faster your model is trained. Then you can use a larger sample size to improve your model accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 2: Machine Learning Pipeline\n",
    "\n",
    "In a new Jupyter Notebook, combine all your codes into a function (or a class). Your new function will execute the complete machine learning pipeline job by receiving the dataset location and output the classifier. This will allow you to use your function to predict the sentiment of any tweet in real time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 3: Apache Spark\n",
    "\n",
    "If you have completed the Apache Spark advanced topic lab, what you can do is to migrate your pipeline from local to a Databricks Notebook. Share your notebook with your instructor and classmates to show off your achievements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
